# yamllint disable rule:line-length
name: Release

'on':
  push:
    tags:
      - "v*"  # Stable releases triggered by version tags
  workflow_dispatch:
    inputs:
      channel:
        description: "Release channel (stable|weekly|nightly)"
        required: false
        default: "nightly"
      upload_r2:
        description: "Also upload built assets to Cloudflare R2 via Wrangler"
        required: false
        default: "false"
      fast_mode:
        description: "Skip packaging & verification steps (speed up local / act runs)"
        required: false
        default: "false"
      macos_only:
        description: "Limit matrix to macOS variants only (skip linux-hosted)"
        required: false
        default: "false"
  workflow_run:
    workflows:
      - Tests
    branches:
      - main
    types:
      - completed

permissions:
  contents: write

jobs:
  warm:
    name: Warm Conan & ccache (matrix)
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux-hosted
            runs_on: ubuntu-latest
            suffix: linux-x86_64
            hosted: true
          - os: macos-hosted-arm64
            runs_on: macos-15
            suffix: macos-arm64
            hosted: true
          - os: macos-hosted-x64
            runs_on: macos-15
            suffix: macos-x86_64
            hosted: true
    runs-on: ${{ matrix.runs_on }}
    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0
          submodules: false
      - name: Skip non-linux entries under act (warm)
        if: github.actor == 'nektos/act' && matrix.os != 'linux-hosted'
        shell: bash
        run: |
          echo "Skipping warm job for ${{ matrix.os }} under act"
          exit 0
      - name: Skip linux-hosted when macos_only=true
        if: inputs.macos_only == 'true' && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          echo "macos_only=true: skipping linux-hosted warm job entry"
          exit 0
      - name: Cache Conan packages
        if: github.actor != 'nektos/act'
        id: cache_conan
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.conan2/p
            ~/.conan2/r
            ~/.conan2/recipes
            ~/.conan2/metadata
            ~/.conan2/s
          key: conan2-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            conan2-${{ runner.os }}-${{ matrix.suffix }}-
            conan2-${{ runner.os }}-
      - name: Cache ccache
        if: github.actor != 'nektos/act'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/ccache
            ~/.ccache
          key: ccache-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            ccache-${{ runner.os }}-${{ matrix.suffix }}-
            ccache-${{ runner.os }}-
      - name: Install dependencies (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends python3-pip python3-setuptools git ccache pkg-config
      - name: Install dependencies (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install ccache pkg-config
      - name: Install Conan
        shell: bash
        run: |
          set -euo pipefail
          if [ "$RUNNER_OS" = "macOS" ]; then
            brew update
            brew install pipx || true
            # Ensure pipx runner PATH and shims are available
            python3 -m pipx ensurepath || true
          else
            sudo apt-get update
            sudo apt-get install -y --no-install-recommends pipx || true
            python3 -m pipx ensurepath || true
          fi
          # Add common user bin to PATH for this job
          [ -d "$HOME/.local/bin" ] && echo "$HOME/.local/bin" >> "$GITHUB_PATH" || true
          export PATH="$HOME/.local/bin:$PATH"
          pipx --version || true
          pipx install --python python3 conan || pipx install conan
          which conan
          conan --version
      - name: Setup Conan
        shell: bash
        run: |
          set -e
          conan profile detect --force
      - name: Warm Conan dependencies
        shell: bash
        run: |
          echo "Warming Conan dependencies for ${{ matrix.suffix }}"
          if [ "$RUNNER_OS" = "macOS" ]; then
            HOST_PROFILE="./conan/profiles/host-macos-apple-clang"
            case "${{ matrix.suffix }}" in
              macos-arm64)
                sed -i '' -E 's/^arch=.*/arch=armv8/' "$HOST_PROFILE"
                ;;
              macos-x86_64)
                cp "$HOST_PROFILE" "$HOST_PROFILE.x86_64"
                sed -i '' -E 's/^arch=.*/arch=x86_64/' "$HOST_PROFILE.x86_64"
                HOST_PROFILE="$HOST_PROFILE.x86_64"
                ;;
            esac
          else
            HOST_PROFILE="./conan/profiles/host-linux-clang"
          fi
          BUILD_PROFILE="default"
          CONAN_ARGS="-of build/warm-release -pr:h=$HOST_PROFILE -pr:b=$BUILD_PROFILE -s build_type=Release -b missing"
          if [ "$RUNNER_OS" = "macOS" ]; then
            case "${{ matrix.suffix }}" in
              macos-arm64) CONAN_ARGS="$CONAN_ARGS -s:h arch=armv8" ;;
              macos-x86_64) CONAN_ARGS="$CONAN_ARGS -s:h arch=x86_64" ;;
            esac
          fi
          conan install . $CONAN_ARGS
      - name: Warm summary
        shell: bash
        run: |
          echo "Conan cache hit: ${{ steps.cache_conan.outputs.cache-hit }}" || true
          du -sh ~/.conan2/p 2>/dev/null || true
          du -sh ~/.cache/ccache 2>/dev/null || true

  build-release:
    name: Build and Package (matrix)
    needs: warm
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux-hosted
            runs_on: ubuntu-latest
            suffix: linux-x86_64
            packaging: tar
            build_packages: true
            meson_args: ""
            hosted: true
          - os: macos-hosted-arm64
            runs_on: macos-15
            suffix: macos-arm64
            packaging: zip
            build_packages: false
            meson_args: "" # arch via profile edit
            hosted: true
          - os: macos-hosted-x64
            runs_on: macos-15
            suffix: macos-x86_64
            packaging: zip
            build_packages: false
            meson_args: "" # arch via profile edit
            hosted: true
    runs-on: ${{ matrix.runs_on }}
    env:
      STAGE_DIR: stage
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Skip non-linux entries under act (build)
        if: github.actor == 'nektos/act' && matrix.os != 'linux-hosted'
        shell: bash
        run: |
          echo "Skipping build-release job steps for ${{ matrix.os }} under act"
          exit 0
      - name: Skip linux-hosted when macos_only=true
        if: inputs.macos_only == 'true' && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          echo "macos_only=true: skipping linux-hosted build-release job entry"
          exit 0
      - name: Verify runner architecture (act diagnostics)
        if: github.actor == 'nektos/act' && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          set -euo pipefail
          ACT_UNAME="$(uname -m || true)"
          echo "Detected uname -m: ${ACT_UNAME}"
          if [ "${ACT_UNAME}" != "x86_64" ]; then
            echo "ERROR: Non-x86_64 architecture detected under act: ${ACT_UNAME}" >&2
            echo "cpuinfo (and other x86-specific code) will not build on this architecture." >&2
            echo "Re-run forcing amd64 containers, e.g.:" >&2
            echo "  act --container-architecture linux/amd64 --job build-release --input fast_mode=true" >&2
            exit 1
          fi

      - name: Cache Conan packages
        if: github.actor != 'nektos/act'
        id: cache_conan
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.conan2/p
            ~/.conan2/r
            ~/.conan2/recipes
            ~/.conan2/metadata
            ~/.conan2/s
          key: conan2-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            conan2-${{ runner.os }}-${{ matrix.suffix }}-
            conan2-${{ runner.os }}-
      - name: Conan cache diagnostics
        if: always()
        shell: bash
        run: |
          echo "Cache hit: ${{ steps.cache_conan.outputs.cache-hit }}"
          for d in p r recipes metadata s; do
            if [ -d "$HOME/.conan2/$d" ]; then
              echo "Directory $d present: $(find $HOME/.conan2/$d -mindepth 1 -maxdepth 1 | wc -l | tr -d ' ')" entries || true
              du -sh $HOME/.conan2/$d 2>/dev/null || true
            else
              echo "Directory $d missing"
            fi
          done
      - name: Cache macOS build directory
        if: runner.os == 'macOS' && github.actor != 'nektos/act'
        uses: actions/cache@v4
        with:
          path: build/release
          key: macos-build-${{ matrix.suffix }}-${{ hashFiles('meson.build', 'meson_options.txt') }}-${{ hashFiles('src/**', 'include/**') }}
          restore-keys: |
            macos-build-${{ matrix.suffix }}-

      - name: Cache ccache
        if: github.actor != 'nektos/act'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/ccache
            ~/.ccache
          key: ccache-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            ccache-${{ runner.os }}-${{ matrix.suffix }}-
            ccache-${{ runner.os }}-

      - name: Install optional system dependencies (Linux only)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          # Add rpm / fakeroot / dpkg-dev so CPack can emit .deb and .rpm packages
          sudo apt-get install -y --no-install-recommends \
            liburing-dev \
            libarchive-dev \
            libtag1-dev \
            pkg-config \
            ccache \
            rpm \
            fakeroot \
            dpkg-dev \
            meson \
            cmake \
            ninja-build \
            clang \
            clang-tools \
            lld
          echo "Installed optional packages: liburing-dev libarchive-dev libtag1-dev ccache rpm fakeroot dpkg-dev meson cmake ninja-build clang clang-tools lld"
          # Ensure compilers are preferred
          echo "CC=clang" >> $GITHUB_ENV
          echo "CXX=clang++" >> $GITHUB_ENV

      - name: Sanitize stdlib flags (macOS only)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # Remove any accidentally injected libstdc++ selections and force libc++
          for var in CXXFLAGS CFLAGS LDFLAGS; do
            current="${!var:-}"
            sanitized="$(echo "$current" | sed -E 's/-stdlib=libstdc\+\+//g') -stdlib=libc++"
            # Collapse whitespace
            sanitized="$(echo "$sanitized" | tr -s ' ')"
            echo "$var=$sanitized" >> "$GITHUB_ENV"
            printf '%s\n' "$var=$sanitized"
          done
          echo "Stdlib flags sanitized for macOS (forcing -stdlib=libc++)."

      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"
          SHORT_HASH=$(git rev-parse --short HEAD)

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          else
            channel="stable"
          fi

          # Derive version and tag
          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
            RELEASE_NAME="YAMS ${VERSION}"
          elif [ "$channel" = "nightly" ]; then
            DATE_ISO=$(date -u +%Y-%m-%d)
            DATE_COMPACT=$(date -u +%Y%m%d)
            VERSION="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            TAG_OUT="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            RELEASE_NAME="YAMS Nightly ${DATE_ISO} (${SHORT_HASH})"
          else # weekly
            YEAR=$(date -u +%G)   # ISO week-numbering year
            WEEK=$(date -u +%V)   # ISO week number 01-53
            VERSION="weekly-${YEAR}w${WEEK}-${SHORT_HASH}"
            TAG_OUT="$VERSION"
            RELEASE_NAME="YAMS Weekly ${YEAR}-w${WEEK} (${SHORT_HASH})"
          fi

          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          echo "release_name=$RELEASE_NAME" >> "$GITHUB_OUTPUT"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT, name=$RELEASE_NAME"

      - name: Download CI benchmark artifacts (-yams, if available)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: benchmark-results-linux-hosted-yams
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI benchmark artifacts (legacy -conan, fallback)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: benchmark-results-linux-hosted-conan
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI coverage (if available)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: coverage-report
          path: ci-artifacts/coverage
          if_no_artifact_found: warn


      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable' && github.actor != 'nektos/act'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      # Hosted runners: install and configure Conan (self-hosted must already be configured)
      - name: Install Conan (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set -euo pipefail
          if [ "$RUNNER_OS" = "macOS" ]; then
            brew update
            brew install pipx || true
            python3 -m pipx ensurepath || true
          else
            sudo apt-get update
            sudo apt-get install -y --no-install-recommends pipx || true
            python3 -m pipx ensurepath || true
          fi
          PY_USER_BIN="$(python3 -m site --user-base 2>/dev/null)/bin"
          [ -d "$PY_USER_BIN" ] && echo "$PY_USER_BIN" >> "$GITHUB_PATH" || true
          [ -d "$HOME/.local/bin" ] && echo "$HOME/.local/bin" >> "$GITHUB_PATH" || true
          export PATH="$HOME/.local/bin:$PY_USER_BIN:$PATH"
          pipx --version || true
          pipx install --python python3 conan || pipx install conan
          which conan || { echo 'Conan not found on PATH after installation'; ls -al "$HOME/.local/bin" || true; exit 127; }
          conan --version
          mkdir -p ~/.conan2
          # Best-effort: global.conf may not exist in repo for hosted macOS
          cp .conan/global.conf ~/.conan2/global.conf 2>/dev/null || true

      - name: Ensure build tools (meson, ninja) for local runners/act
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set -euo pipefail
          if [ "$RUNNER_OS" = "macOS" ]; then
            brew update || true
            brew install meson ninja ccache || true
          else
            python3 -m pip install --user --upgrade meson 'ninja>=1.10' || python -m pip install --user --upgrade meson 'ninja>=1.10'
            if [ -n "${GITHUB_PATH:-}" ]; then
              echo "$HOME/.local/bin" >> "$GITHUB_PATH"
            else
              export PATH="$HOME/.local/bin:$PATH"
            fi
          fi
          echo "meson version: $(meson --version || true)"
          echo "ninja version: $(ninja --version || true)"

      - name: Ensure meson and ninja (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # If meson or ninja are not on PATH, install via Homebrew for robustness
          NEED_INSTALL=0
          command -v meson >/dev/null 2>&1 || NEED_INSTALL=1
          command -v ninja >/dev/null 2>&1 || NEED_INSTALL=1
          if [ "$NEED_INSTALL" -eq 1 ]; then
            brew update || true
            brew install meson ninja || true
          fi
          echo "meson version (post-check): $(meson --version || echo 'missing')"
          echo "ninja version (post-check): $(ninja --version || echo 'missing')"

      - name: Setup ccache env
        shell: bash
        run: |
          echo "CCACHE_DIR=$HOME/.cache/ccache" >> $GITHUB_ENV
          echo "CCACHE_BASEDIR=$GITHUB_WORKSPACE" >> $GITHUB_ENV
          echo "CCACHE_COMPRESS=1" >> $GITHUB_ENV
          echo "CCACHE_MAXSIZE=700M" >> $GITHUB_ENV
          ccache -z 2>/dev/null || true

      - name: Setup Conan (hosted Linux/macOS)
        if: ${{ matrix.hosted  }}
        shell: bash
        run: |
          set -e
          conan profile detect --force
          echo "Conan detected default profile. A platform-specific profile (host-macos-apple-clang or host-linux-clang) will be applied explicitly later."

      - name: Detect clang version (log only)
        shell: bash
        run: |
          set -euo pipefail
          # Prefer clang++, fallback to clang
            if command -v clang++ >/dev/null 2>&1; then
              RAW_VER=$(clang++ --version | sed -n 's/.*version recently[0-9][0-9]*).*/\1/p' | head -1 || true)
            elif command -v clang >/dev/null 2>&1; then
              RAW_VER=$(clang --version | sed -n 's/.*version recently[0-9][0-9]*).*/\1/p' | head -1 || true)
            else
              RAW_VER=""
            fi
            if [ -z "$RAW_VER" ]; then
              echo "Could not auto-detect clang version; using profile defaults" >&2
            else
              echo "Detected clang major: $RAW_VER"
            fi
      - name: Compare profile vs detected clang (advice)
        shell: bash
        run: |
          set -euo pipefail
          PROFILE_FILE="./conan/profiles/host-linux-clang"
          if [ -f "$PROFILE_FILE" ]; then
            PROFILE_VER=$(grep -E '^compiler.version=' "$PROFILE_FILE" | sed -E 's/.*=//')
          else
            PROFILE_VER="(missing profile)"
          fi
          if command -v clang++ >/dev/null 2>&1; then
            SYS_VER=$(clang++ --version | sed -n 's/.*version recently[0-9][0-9]*).*/\1/p' | head -1 || true)
          elif command -v clang >/dev/null 2>&1; then
            SYS_VER=$(clang --version | sed -n 's/.*version recently[0-9][0-9]*).*/\1/p' | head -1 || true)
          else
            SYS_VER="unknown"
          fi
          echo "Profile declares clang version: $PROFILE_VER"
          echo "System detected clang version: $SYS_VER"
          if [ -n "$SYS_VER" ] && [ "$SYS_VER" != "unknown" ] && [ "$PROFILE_VER" != "$SYS_VER" ]; then
            echo "NOTE: Mismatch between profile (clang $PROFILE_VER) and system (clang $SYS_VER)." >&2
            echo "      Consider either installing clang-$PROFILE_VER or adjusting profile to $SYS_VER for local/act runs to avoid subtle ABI or flag differences." >&2
          fi

      - name: Check Conan (self-hosted sanity)
        if: ${{ !matrix.hosted }}
        shell: bash
        run: conan --version || echo "Conan is expected to be pre-installed and configured on self-hosted runners"

      # Hosted runners: clean corrupted cache if needed
      - name: Clean corrupted Conan cache if needed (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          if ! conan list "*" 2>/dev/null;
          then
            echo "Conan cache appears corrupted, cleaning locks and temp files..."
            conan cache clean --locks --temp 2>/dev/null || true
            echo "Conan cache locks/temp cleaned"
          fi

      - name: Install pkg-config (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          brew update
          brew install pkg-config cmake ninja || true

      - name: Tune Conan client (parallel downloads)
        shell: bash
        run: |
          set -euo pipefail
          CONF_FILE="$HOME/.conan2/global.conf"
          LINE="core.download:parallel=8"
          mkdir -p "$(dirname "$CONF_FILE")"
          if [ -f "$CONF_FILE" ]; then
            TMP_FILE="$(mktemp)"
            awk -v line="$LINE" '
              BEGIN { replaced = 0 }
              /^core.download:parallel=/ { if (!replaced) { print line; replaced = 1 } ; next }
              { print }
              END { if (!replaced) print line }
            ' "$CONF_FILE" > "$TMP_FILE"
            mv "$TMP_FILE" "$CONF_FILE"
          else
            printf '%s\n' "$LINE" > "$CONF_FILE"
          fi
          echo "Configured $LINE in $CONF_FILE"
          grep -n '^core.download:parallel=' "$CONF_FILE" || true
          conan config show core.download:parallel 2>/dev/null || true
          conan --version

      - name: Warm key Conan packages (best-effort)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set +e
          # Try to prefetch heavy packages to minimize build-time compiles
          for ref in \
            openjpeg/2.5.3 \
            pdfium/95.0.4629 \
            onnxruntime/1.18.1 \
            icu/74.1 \
            libarchive/3.7.6; do
            echo "Prefetching $ref ..." || true
            conan download "$ref" -r=conancenter || true
          done
          set -e

      # Release build for ALL targets
      - name: Configure and Build Release (Optimized)
        shell: bash
        run: |
          echo "Optimized release build for ${{ matrix.suffix }}"
          # Align build directory with README (build/release)
          rm -rf build/release
          if [ "$RUNNER_OS" = "macOS" ]; then
            HOST_PROFILE="./conan/profiles/host-macos-apple-clang"
            case "${{ matrix.suffix }}" in
              macos-arm64)
                sed -i '' -E 's/^arch=.*/arch=armv8/' "$HOST_PROFILE"
                ;;
              macos-x86_64)
                cp "$HOST_PROFILE" "$HOST_PROFILE.x86_64"
                sed -i '' -E 's/^arch=.*/arch=x86_64/' "$HOST_PROFILE.x86_64"
                HOST_PROFILE="$HOST_PROFILE.x86_64"
                ;;
            esac
          else
            HOST_PROFILE="./conan/profiles/host-linux-clang"
          fi
          BUILD_PROFILE="default"
          CONAN_ARGS="-of build/release -pr:h=$HOST_PROFILE -pr:b=$BUILD_PROFILE -s build_type=Release -b missing"
          if [ "$RUNNER_OS" = "macOS" ]; then
            case "${{ matrix.suffix }}" in
              macos-arm64) CONAN_ARGS="$CONAN_ARGS -s:h arch=armv8" ;;
              macos-x86_64) CONAN_ARGS="$CONAN_ARGS -s:h arch=x86_64" ;;
            esac
          fi
          conan install . $CONAN_ARGS
          # Load Conan-generated environment (PKG_CONFIG_PATH, CFLAGS/LDFLAGS, etc.)
          if [ -f "build/release/build-release/conan/conanrun.sh" ]; then
            source build/release/build-release/conan/conanrun.sh
          fi
          # Resolve Conan Meson toolchain file robustly across Conan versions
          TOOLCHAIN_DIR="build/release/build-release/conan"
          NATIVE_FILE="$TOOLCHAIN_DIR/conan_meson_native.ini"
          CROSS_FILE="$TOOLCHAIN_DIR/conan_meson_cross.ini"
          if [ -f "$NATIVE_FILE" ]; then
            MESON_TOOL_ARG=(--native-file "$NATIVE_FILE")
          elif [ -f "$CROSS_FILE" ]; then
            MESON_TOOL_ARG=(--cross-file "$CROSS_FILE")
          else
            echo "Meson toolchain file not found in $TOOLCHAIN_DIR; listing directory for diagnostics:" >&2
            ls -al "$TOOLCHAIN_DIR" >&2 || true
            # Last resort: search within build/release for either native or cross file
            FOUND=$(find build/release -maxdepth 3 -type f \( -name 'conan_meson_native.ini' -o -name 'conan_meson_cross.ini' \) | head -n1)
            if [ -n "$FOUND" ]; then
              case "$FOUND" in
                *native*) MESON_TOOL_ARG=(--native-file "$FOUND") ;;
                *cross*) MESON_TOOL_ARG=(--cross-file "$FOUND") ;;
              esac
            else
              echo "ERROR: Cannot find specified Meson toolchain file" >&2
              exit 1
            fi
          fi
          # Ensure pkg-config is discoverable in cross build; use Homebrew path explicitly
          export PKG_CONFIG=${PKG_CONFIG:-/opt/homebrew/bin/pkg-config}
          meson setup build/release "${MESON_TOOL_ARG[@]}" \
            -Dwerror=false -Dwarning_level=2 -Denable-lzma=auto
          meson compile -C build/release
          echo "BUILD_DIR=build/release" >> $GITHUB_ENV

      - name: ccache stats (post-build)
        shell: bash
        run: |
          ccache -s || echo "ccache stats unavailable"

      - name: Collect benchmark results
        shell: bash
        run: |
          mkdir -p "$BUILD_DIR/bench_results"
          # Collect from validation build (if Linux hosted ran validation)
          if [ -f "build/release/bench_results.json" ]; then
            cp build/release/bench_results.json "$BUILD_DIR/bench_results/"
            echo "Collected benchmark results from validation build"
          fi
          # Also check CI artifacts if available
          if [ -d "ci-artifacts/benchmarks" ] && [ "$(ls -A ci-artifacts/benchmarks/*.json 2>/dev/null)" ]; then
            cp ci-artifacts/benchmarks/*.json "$BUILD_DIR/bench_results/" || true
          fi

      - name: Install
        shell: bash
        run: |
          # Ensure BUILD_DIR is properly set
          if [ ! -d "$BUILD_DIR" ]; then
            echo "BUILD_DIR not found at $BUILD_DIR, attempting fallback to build/release (legacy path build/yams-release no longer used)." >&2
            exit 1
          fi
          # Install to an absolute stage path under the build dir to avoid path duplication
          BD="$(cd "$BUILD_DIR" && pwd)"
          meson install -C "$BD" --destdir "$BD/stage"
          if [ ! -d "$BD/stage" ]; then
            echo "Stage directory missing after meson install" >&2
            ls -al "$BD" >&2 || true
            exit 1
          fi
          echo "STAGE_DIR=$BD/stage" >> "$GITHUB_ENV"

      - name: Generate release summary
        shell: bash
        run: |
          SUMMARY_FILE="$BUILD_DIR/release_summary.md"
          echo "## Release Build Information (${{ steps.meta.outputs.version }})" > "$SUMMARY_FILE"
          echo "" >> "$SUMMARY_FILE"
          echo "**Platform:** ${{ matrix.suffix }}" >> "$SUMMARY_FILE"
          echo "**Build Type:** Release" >> "$SUMMARY_FILE"
          echo "**Channel:** ${{ steps.meta.outputs.channel }}" >> "$SUMMARY_FILE"

          # Only mention CI validation if we actually have CI artifacts
          if [ -d "ci-artifacts" ] && [ "$(ls -A ci-artifacts/ 2>/dev/null)" ]; then
            echo "**CI Status:** Tests and benchmarks from CI workflow" >> "$SUMMARY_FILE"
          fi
          echo "" >> "$SUMMARY_FILE"

          # Add coverage information if available (no python dependency)
          if [ -f "ci-artifacts/coverage/coverage.xml" ]; then
            echo "### Test Coverage" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            # Extract line-rate="0.8234" attribute and convert to percent with one decimal
            raw_rate=$(grep -Eo 'line-rate="[0-9.]+"' ci-artifacts/coverage/coverage.xml | head -1 | sed -E 's/.*="([0-9.]+)"/\1/') || raw_rate=""
            if [ -n "$raw_rate" ]; then
              # Use awk for safe float multiplication & formatting
              coverage_pct=$(awk -v r="$raw_rate" 'BEGIN{ printf("%.1f%%", r*100) }')
            else
              coverage_pct="N/A"
            fi
            echo "**Line Coverage:** $coverage_pct" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
          fi

          # Add benchmark results if available from CI or validation (jq preferred, fallback to grep)
          if [ -d "$BUILD_DIR/bench_results" ] && ls "$BUILD_DIR/bench_results"/*.json >/dev/null 2>&1; then
            echo "### Performance Metrics" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            echo "| Benchmark | Time (ns/op) | CPU (ns/op) | Memory |" >> "$SUMMARY_FILE"
            echo "|-----------|--------------|-------------|--------|" >> "$SUMMARY_FILE"
            if command -v jq >/dev/null 2>&1; then
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                jq -r '.benchmarks[]? | "| ".name // "Unknown" | ".real_time // 0 | floor) | ".cpu_time // 0 | floor) | "' "$json_file" 2>/dev/null | while IFS= read -r line; do
                  name=$(echo "$line" | cut -d'|' -f2 | sed 's/^ *//;s/ *$//')
                  rtime=$(echo "$line" | cut -d'|' -f3 | tr -d ' ')
                  ctime=$(echo "$line" | cut -d'|' -f4 | tr -d ' ')
                  # Derive memory throughput if bytes_per_second present
                  mem=$(jq -r --arg n "$name" '.benchmarks[]? | select(.name==$n) | if (.bytes_per_second // 0) > 0 then ((.bytes_per_second/1024/1024)|tostring)+" MB/s" else (if (.items_per_second // 0) > 0 then ((.items_per_second)|tostring)+" ops/s" else "N/A" end) end' "$json_file" 2>/dev/null)
                  [ -z "$mem" ] && mem="N/A"
                  echo "| $name | $rtime | $ctime | $mem |" >> "$SUMMARY_FILE"
                done
              done
            else
              # Minimal fallback: grep fields (less robust)
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                grep '"name"' "$json_file" | sed -E 's/.*"name": *"([^"]+)".*/| \1 | ? | ? | N/A |/' >> "$SUMMARY_FILE" || true
              done
            fi
            echo "" >> "$SUMMARY_FILE"
          fi

          echo "Generated release summary at: $SUMMARY_FILE"
          cat "$SUMMARY_FILE"

      - name: Package
        if: ${{ inputs.fast_mode != 'true' && github.actor != 'nektos/act' }}
        shell: bash
        run: |
          STAGE_PATH="${{ env.STAGE_DIR }}"
          if [ ! -d "$STAGE_PATH" ]; then
            echo "Stage directory not found at $STAGE_PATH" >&2
            ls -al "$BUILD_DIR" >&2 || true
            exit 1
          fi
          cd "$STAGE_PATH"
          VERSION="${{ steps.meta.outputs.version }}"
          SUFFIX="${{ matrix.suffix }}"
          OUTDIR="$GITHUB_WORKSPACE"
          if [ "${{ matrix.packaging }}" = "zip" ]; then
            ASSET="yams-${VERSION}-${SUFFIX}.zip"
            zip -r "$OUTDIR/$ASSET" .
          else
            ASSET="yams-${VERSION}-${SUFFIX}.tar.gz"
            tar czf "$OUTDIR/$ASSET" .
          fi
          echo "ASSET_PATH=$OUTDIR/$ASSET" >> "$GITHUB_ENV"
          echo "Created asset: $OUTDIR/$ASSET"

      - name: Build Linux packages (DEB/RPM)
        if: ${{ matrix.build_packages == true && matrix.os == 'linux-hosted' && inputs.fast_mode != 'true' && github.actor != 'nektos/act' }}
        shell: bash
        run: |
          chmod +x scripts/build-deb.sh
          scripts/build-deb.sh "${{ steps.meta.outputs.version }}" "${{ env.BUILD_DIR }}"

      # Release notes are sourced directly from CHANGELOG.md during release creation

      - name: Publish matrix.json (expected platform count)
        if: matrix.os == 'linux-hosted'
        shell: bash
        run: |
          # Only generate once (linux-hosted) to avoid artifact name collision across matrix entries.
          # Update to reflect current matrix total (3 platforms)
          echo '{"total": 3}' > matrix.json

      - name: Upload matrix metadata
        if: matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: actions/upload-artifact@v4
        with:
          name: matrix-meta
          path: matrix.json
          retention-days: 1

      - name: Upload Release Artifacts
        if: github.actor != 'nektos/act'
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ matrix.suffix }}-files${{ github.run_attempt > 1 && format('-a{0}', github.run_attempt) || '' }}
          path: |
            yams-*.tar.gz
            yams-*.zip
            ${{ env.BUILD_DIR }}/release_summary.md
            ${{ env.BUILD_DIR }}/bench_results/*.json
            yams-*.deb
            yams-*.rpm
            yams-*.AppImage
            yams-*.pkg
          retention-days: 1

      - name: Verify Linux package artifacts
        if: ${{ matrix.os == 'linux-hosted' && github.actor != 'nektos/act' && inputs.fast_mode != 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          echo "Verifying expected Linux package artifacts (DEB/RPM)"
          ls -1 yams-*linux-x86_64.deb 2>/dev/null || { echo "ERROR: Missing .deb package" >&2; exit 1; }
          if command -v rpmbuild >/dev/null 2>&1; then
            ls -1 yams-*linux-x86_64.rpm 2>/dev/null || { echo "ERROR: Missing .rpm package" >&2; exit 1; }
          else
            echo "rpmbuild unavailable; RPM check skipped" >&2
          fi
          echo "Linux package verification complete"

  create-release:
    name: Create GitHub Release
    needs: build-release
    runs-on: ubuntu-latest
    # Skip release creation entirely when running under act
    if: always() && !cancelled() && github.actor != 'nektos/act'
    permissions:
      contents: write
      actions: read
    env:
      CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
      CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      CLOUDFLARE_ENDPOINT: ${{ secrets.CLOUDFLARE_ENDPOINT }}
      R2_PREFIX: ${{ secrets.R2_PREFIX }}
      R2_BUCKET: ${{ secrets.R2_BUCKET }}
    steps:
      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"
          SHORT_HASH=$(git rev-parse --short HEAD)

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          else
            channel="stable"
          fi

          # Derive version and tag
          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
            RELEASE_NAME="YAMS ${VERSION}"
          elif [ "$channel" = "nightly" ]; then
            DATE_ISO=$(date -u +%Y-%m-%d)
            DATE_COMPACT=$(date -u +%Y%m%d)
            VERSION="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            TAG_OUT="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            RELEASE_NAME="YAMS Nightly ${DATE_ISO} (${SHORT_HASH})"
          else # weekly
            YEAR=$(date -u +%G)   # ISO week-numbering year
            WEEK=$(date -u +%V)   # ISO week number 01-53
            VERSION="weekly-${YEAR}w${WEEK}-${SHORT_HASH}"
            TAG_OUT="$VERSION"
            RELEASE_NAME="YAMS Weekly ${YEAR}-w${WEEK} (${SHORT_HASH})"
          fi

          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          echo "release_name=$RELEASE_NAME" >> "$GITHUB_OUTPUT"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT, name=$RELEASE_NAME"

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts
          pattern: "*"

      - name: List downloaded artifacts (debug)
        shell: bash
        run: |
          echo "Downloaded artifact directories:" >&2
          find release-artifacts -maxdepth 2 -type f -printf '%P\n' 2>/dev/null || true

      - name: Collect assets into staging directory
        shell: bash
        run: |
          set -euo pipefail
          rm -rf assets || true
          mkdir -p assets
          # Collect all per-platform release artifacts
          for dir in release-artifacts/release-*; do
            [ -d "$dir" ] || continue
            # Archives
            cp -v $dir/*.tar.gz assets/ 2>/dev/null || true
            cp -v $dir/*.zip assets/ 2>/dev/null || true
            # Packages
            cp -v $dir/*.deb assets/ 2>/dev/null || true
            cp -v $dir/*.rpm assets/ 2>/dev/null || true
            cp -v $dir/*.AppImage assets/ 2>/dev/null || true
            # Summaries & bench json
            if [ -d "$dir/bench_results" ]; then
              cp -v $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
            if [ -f "$dir/release_summary.md" ]; then
              cp -v "$dir/release_summary.md" "assets/release_summary-$(basename "$dir").md" 2>/dev/null || true
            fi
          done
          echo "Final assets content:" >&2
          ls -al assets >&2 || true

      - name: Generate checksums
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "Generating SHA256SUMS for release assets" >&2
          # Exclude bench JSON and summaries from checksum manifest (only distributable binaries)
          ls -1 | grep -E '\.(tar.gz|zip|deb|rpm|AppImage|pkg)$' | while read -r f; do
            sha256sum "$f" >> SHA256SUMS
          done
          sort -o SHA256SUMS SHA256SUMS
          echo "Created checksum manifest:" >&2
          cat SHA256SUMS >&2

      - name: Install Wrangler CLI
        if: (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.upload_r2 == 'true')) && env.CLOUDFLARE_ACCOUNT_ID != '' && env.CLOUDFLARE_API_TOKEN != ''
        shell: bash
        run: |
          npm i -g wrangler

      - name: Upload assets to Cloudflare R2 (Wrangler)
        if: (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.upload_r2 == 'true')) && env.CLOUDFLARE_ACCOUNT_ID != '' && env.CLOUDFLARE_API_TOKEN != ''
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ENDPOINT: ${{ secrets.CLOUDFLARE_ENDPOINT }}
          R2_PREFIX: ${{ secrets.R2_PREFIX }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          # Resolve bucket name: prefer secret R2_BUCKET, else parse wrangler.toml if present
          BUCKET="${R2_BUCKET:-}"
          if [ -z "$BUCKET" ] && [ -f "$GITHUB_WORKSPACE/cloudflare/worker/wrangler.toml" ]; then
            BUCKET=$(sed -n 's/^bucket_name\s*=\s*"\(.*\)"/ recently1/p' "$GITHUB_WORKSPACE/cloudflare/worker/wrangler.toml" | head -1)
          fi
          if [ -z "$BUCKET" ]; then
            echo "Skipping R2 upload: no R2_BUCKET secret and wrangler.toml missing or without bucket_name." >&2
            exit 0
          fi
          echo "Uploading to R2 bucket: $BUCKET (prefix='${R2_PREFIX:-}')"
          # Upload distributable assets
          shopt -s nullglob
          for f in *.tar.gz *.zip *.deb *.rpm *.AppImage; do
            [ -f "$f" ] || continue
            case "$f" in
              *.deb)
                DEST="${BUCKET}/${R2_PREFIX:-}apt/${f}"
                wrangler r2 object put "$DEST" --file="$f" --content-type application/vnd.debian.binary-package
                ;;
              *.rpm)
                DEST="${BUCKET}/${R2_PREFIX:-}yum/${f}"
                wrangler r2 object put "$DEST" --file="$f" --content-type application/x-rpm
                ;;
              *)
                DEST="${BUCKET}/${R2_PREFIX:-}${f}"
                wrangler r2 object put "$DEST" --file="$f"
                ;;
            esac
          done
          # Upload latest.json with JSON content-type
          if [ -f latest.json ]; then
            wrangler r2 object put "${BUCKET}/${R2_PREFIX:-}latest.json" --file=latest.json --content-type application/json
          fi

      - name: (Optional) Import GPG key and sign checksums
        if: env.GPG_PRIVATE_KEY && env.GPG_PRIVATE_KEY != ''
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY || '' }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE || '' }}
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "GPG key present: generating detached signature for SHA256SUMS" >&2
          echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --import
          gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --detach-sign --armor -o SHA256SUMS.asc SHA256SUMS
          echo "Signature generated (SHA256SUMS.asc)" >&2

      - name: Verify asset set
        id: asset_check
        shell: bash
        run: |
          COUNT=$(find assets -type f | wc -l | tr -d ' ')
          echo "Discovered $COUNT asset files" >&2
          echo "file_count=$COUNT" >> $GITHUB_OUTPUT
          if [ "$COUNT" -eq 0 ]; then
            echo "ERROR: No asset files assembled for release." >&2
            exit 1
          fi

      - name: Generate Homebrew formula (stable only)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          TAG="${{ steps.meta.outputs.tag }}"
          VERSION="${{ steps.meta.outputs.version }}"
          FORMULA_DIR="homebrew"
          mkdir -p "$FORMULA_DIR"
          ARCHIVE_URL="https://github.com/${{ github.repository }}/archive/refs/tags/${TAG}.tar.gz"
          echo "Downloading source tarball: $ARCHIVE_URL" >&2
          TARBALL="${TAG}.tar.gz"
          curl -Ls -o "$TARBALL" "$ARCHIVE_URL"
          SHA256=$(shasum -a 256 "$TARBALL" | awk '{print $1}')
          echo "Computed sha256: $SHA256" >&2
          TEMPLATE_PATH="packaging/homebrew/yams.rb.template"
          if [ ! -f "$TEMPLATE_PATH" ]; then
            echo "ERROR: Homebrew template not found at $TEMPLATE_PATH" >&2
            exit 1
          fi
          OUT_FORMULA="$FORMULA_DIR/yams.rb"
          # Replace template placeholders with release metadata
          sed \
            -e "s|__VERSION__|$VERSION|g" \
            -e "s|__SHA256__|$SHA256|g" \
            "$TEMPLATE_PATH" > "$OUT_FORMULA"
          echo "Updated formula at $OUT_FORMULA:" >&2
          grep -E 'version\s+"|sha256 "' "$OUT_FORMULA" >&2 || true
          # Create quick install instructions file
          cat > "$FORMULA_DIR/README.txt" <<EOF
          Homebrew formula generated for YAMS $VERSION
          To use without a tap:
            brew install --build-from-source $OUT_FORMULA

          Recommended (create a tap repository and place yams.rb there), e.g.:
            1. Create repo: github.com/<you>/homebrew-yams
            2. Add this formula as Formula/yams.rb
            3. Users run: brew install <you>/yams/yams
          EOF

      - name: Update Homebrew tap submodule (stable only)
        if: steps.meta.outputs.channel == 'stable'
        env:
          HOMEBREW_TAP_TOKEN: ${{ secrets.HOMEBREW_TAP_TOKEN || '' }}
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAP_PATH="taps/homebrew-yams"
          if [ ! -d "$TAP_PATH" ]; then
            echo "Tap submodule not found at $TAP_PATH; skipping tap update" >&2
            exit 0
          fi
          if [ ! -f "homebrew/yams.rb" ]; then
            echo "homebrew/yams.rb not found; skipping tap update" >&2
            exit 0
          fi
          git submodule update --init --recursive
          mkdir -p "$TAP_PATH/Formula"
          cp homebrew/yams.rb "$TAP_PATH/Formula/yams.rb"
          pushd "$TAP_PATH" >/dev/null
          git checkout -B "update/formula-v${VERSION}"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add Formula/yams.rb || true
          if git diff --cached --quiet; then
            echo "Tap formula unchanged; skipping push" >&2
            popd >/dev/null
            exit 0
          fi
          git commit -m "chore(homebrew): update formula to v${VERSION}"
          if [ -n "${HOMEBREW_TAP_TOKEN:-}" ]; then
            REMOTE="https://x-access-token:${HOMEBREW_TAP_TOKEN}@github.com/${{ github.repository_owner }}/homebrew-yams.git"
            git push --set-upstream "$REMOTE" "update/formula-v${VERSION}" || echo "Push failed; ensure HOMEBREW_TAP_TOKEN has repo permissions"
          else
            echo "HOMEBREW_TAP_TOKEN not set; manual push required" >&2
          fi
          popd >/dev/null

      - name: Build APT repository metadata (stable only, linux .deb present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          # Require at least one .deb in assets
          if ! ls assets/*.deb >/dev/null 2>&1; then
            echo "No .deb found; skipping APT repo generation" >&2
            exit 0
          fi
          BASE_VERSION="${{ steps.meta.outputs.base_version }}"
          REPO_ROOT="aptrepo"
          POOL_DIR="$REPO_ROOT/pool/main/y/yams"
          DIST=stable
          COMPONENT=main
          ARCH=amd64
          mkdir -p "$POOL_DIR" "$REPO_ROOT/dists/$DIST/$COMPONENT/binary-$ARCH"
          # Copy & normalize deb naming (yams_<version>_amd64.deb)
          for deb in assets/*.deb; do
            cp "$deb" "$POOL_DIR/$(echo "$deb" | sed -E "s|.*yams-([^-]+)-linux-x86_64\.deb|yams_${BASE_VERSION}_amd64.deb|")" || true
          done
          # Install dpkg-dev if missing (for dpkg-scanpackages)
          if ! command -v dpkg-scanpackages >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y dpkg-dev
          fi
          pushd "$REPO_ROOT" >/dev/null
          dpkg-scanpackages --multiversion pool > dists/$DIST/$COMPONENT/binary-$ARCH/Packages
          gzip -c dists/$DIST/$COMPONENT/binary-$ARCH/Packages > dists/$DIST/$COMPONENT/binary-$ARCH/Packages.gz
          cat > dists/$DIST/Release <<REL
          Origin: YAMS
          Label: YAMS
          Suite: $DIST
          Codename: $DIST
          Architectures: $ARCH
          Components: $COMPONENT
          Description: YAMS APT repository
          REL
          # Optional GPG signing if secret present
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes -abs -o dists/$DIST/Release.gpg dists/$DIST/Release
            gpg --batch --yes --clearsign -o dists/$DIST/InRelease dists/$DIST/Release
          fi
          popd >/dev/null
          tree "$REPO_ROOT" || find "$REPO_ROOT" -maxdepth 4 -type f -print
          cat > "$REPO_ROOT/USAGE.txt" <<EOF
          Add this APT repo (unsigned example):
            curl -fsSL https://${{ github.repository_owner }}.pages.dev/aptrepo/gpg.key -o /usr/share/keyrings/yams.gpg   # (If you later publish a key)
            echo "deb [signed-by=/usr/share/keyrings/yams.gpg] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams

          If unsigned (temporary/testing):
            echo "deb [trusted=yes] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams
          EOF

      - name: Upload APT repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: apt-repo
          path: aptrepo/
          retention-days: 7

      - name: Build YUM repository metadata (stable only, rpm present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          if ! ls assets/*.rpm >/dev/null 2>&1; then
            echo "No .rpm found; skipping YUM repo generation" >&2
            exit 0
          fi
          YUM_ROOT="yumrepo"
          mkdir -p "$YUM_ROOT"
          cp assets/*.rpm "$YUM_ROOT/" 2>/dev/null || true
          # Install createrepo_c if needed
          if ! command -v createrepo_c >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y createrepo-c
          fi

          createrepo_c "$YUM_ROOT"
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes --detach-sign --armor -o "$YUM_ROOT/repodata/repomd.xml.asc" "$YUM_ROOT/repodata/repomd.xml"
          fi
          cat > "$YUM_ROOT/USAGE.txt" <<EOF
          Add YUM/DNF repo (unsigned example):
            sudo tee /etc/yum.repos.d/yams.repo <<'REPO'
            [yams]
            name=YAMS Repository
            baseurl=https://${{ github.repository_owner }}.pages.dev/yumrepo/
            enabled=1
            gpgcheck=0
            repo_gpgcheck=0
            REPO

          Then install:
            sudo dnf makecache || sudo yum makecache
            sudo dnf install yams || sudo yum install yams

          (Enable gpgcheck once you publish a key and sign RPMs/repodata.)
          EOF

      - name: Upload YUM repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: yum-repo
          path: yumrepo/
          retention-days: 7

      - name: Generate latest manifest (latest.json)
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAG="${{ steps.meta.outputs.tag }}"
            CHANNEL="${{ steps.meta.outputs.channel }}"
          DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          mkdir -p assets
          cd assets
          if [ ! -f SHA256SUMS ]; then
            echo "Missing SHA256SUMS file in assets/; cannot build manifest" >&2
            ls -al >&2 || true
            exit 1
          fi
          # Build assets array JSON using awk (avoid jq dependency); trim trailing comma
          ASSETS_JSON=$(awk '{printf "{\"name\":\"%s\",\"sha256\":\"%s\"},", $2, $1}' SHA256SUMS | sed 's/,$//')
          cat > latest.json <<LJSON
          {
            "version": "${VERSION}",
            "tag": "${TAG}",
            "channel": "${CHANNEL}",
            "published_at": "${DATE}",
            "assets": [${ASSETS_JSON}]
          }
          LJSON
          echo "latest.json manifest (assets/latest.json):" >&2
          sed 's/^/  /' latest.json >&2

      - name: Check existing release (stable only)
        id: existing_release
        shell: bash
        run: |
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Checking if release $TAG already exists" >&2
          if command -v gh >/dev/null 2>&1; then
            if gh release view "$TAG" >/dev/null 2>&1; then
              echo "exists=true" >> $GITHUB_OUTPUT
            else
              echo "exists=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "gh CLI not installed; skipping existence check" >&2
            echo "exists=unknown" >> $GITHUB_OUTPUT
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Check job completion status
        id: check-status
        shell: bash
        run: |
          # Discover expected platforms from matrix job names in this run
          JOBS_JSON=$(curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                           -H "Accept: application/vnd.github.v3+json" \
                           -s "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100")
          # Extract unique platform identifiers from "Build and Release (<platform>)" job names
          EXPECTED_PLATFORMS=$(echo "$JOBS_JSON" | sed -n 's/.*"name"[[:space:]]*:[[:space:]]*"\(Build and Release ([^\"]*)\)".*/\1/p' | sed -n 's/Build and Release (\(.*\))/\1/p' | sort -u)
          TOTAL_EXPECTED=$(echo "$EXPECTED_PLATFORMS" | grep -c . || true)

          # Count successful artifacts from downloaded files (release-*)
          if [ -d "release-artifacts" ]; then
            # Count per-platform artifact directories (robust against file/dir listing quirks)
            SUCCESS_COUNT=$(find "release-artifacts" -mindepth 1 -maxdepth 1 -type d -name 'release-*' 2>/dev/null | grep -c . || true)
          else
            SUCCESS_COUNT=0
          fi

          # Determine expected builds:
          # 1) Prefer matrix.json (if provided)
          # 2) Otherwise, fall back to number of artifact groups downloaded
          if [ -f "release-artifacts/matrix.json" ]; then
            TOTAL_EXPECTED=$(cat "release-artifacts/matrix.json" | tr -d '\r' | grep -Eo '"total"[[:space:]]*:[[:space:]]*[0-9]+' | grep -Eo '[0-9]+' | head -1)
          fi
          if [ -z "$TOTAL_EXPECTED" ] || [ "$TOTAL_EXPECTED" -eq 0 ]; then
            TOTAL_EXPECTED="$SUCCESS_COUNT"
          fi

          # Compute dynamic threshold = ceil(TOTAL_EXPECTED / 2)
          THRESHOLD=$(( (TOTAL_EXPECTED + 1) / 2 ))

          echo "Successful builds: $SUCCESS_COUNT out of $TOTAL_EXPECTED (threshold: $THRESHOLD)"

          if [ "$SUCCESS_COUNT" -lt "$THRESHOLD" ]; then
            echo "ERROR: Need at least $THRESHOLD successful builds to create release (out of $TOTAL_EXPECTED expected)"
            exit 1
          fi

          echo "success_count=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "total_expected=$TOTAL_EXPECTED" >> $GITHUB_OUTPUT
          echo "threshold=$THRESHOLD" >> $GITHUB_OUTPUT

      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      - name: Extract grouped changelogs for minor version (stable only)
        id: grouped-changelog
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          # Extract minor version from current tag
          CURRENT_VERSION="${{ steps.meta.outputs.version }}"
          MINOR_VERSION=$(echo "$CURRENT_VERSION" | sed -E 's/^v?([0-9]+\.[0-9]+).*/\1/')

          echo "Current version: $CURRENT_VERSION"
          echo "Extracting all changes for minor version: $MINOR_VERSION"

          # Create grouped changelog file
          GROUPED_FILE="grouped_changelog_${MINOR_VERSION}.md"

          # Extract all entries for this minor version from CHANGELOG.md
          echo "# Release Notes for v${MINOR_VERSION}.x Series" > "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"
          echo "This release is part of the v${MINOR_VERSION}.x series. Below are all changes in this series:" >> "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"

          # Parse CHANGELOG.md and extract all sections matching the minor version
          awk -v minor="$MINOR_VERSION" ' 
            /^## \[v?[0-9]+\.[0-9]+\.[0-9]+/ {
              version_str = $2
              gsub(/ \[v?/, "", version_str)
              gsub(/ /, "", version_str)
              split(version_str, version_parts, ".")
              version_minor = version_parts[1] "." version_parts[2]

              if (version_minor == minor) {
                in_section = 1
                print $0
                next
              } else {
                in_section = 0
              }
            }
            /^## \[/ && in_section { in_section = 0 }
            in_section { print }
          ' CHANGELOG.md >> "$GROUPED_FILE"

          # Store path for later use
          echo "grouped_changelog_file=$GROUPED_FILE" >> $GITHUB_OUTPUT
          echo "minor_version=$MINOR_VERSION" >> $GITHUB_OUTPUT

      - name: Prepare release assets
        shell: bash
        run: |
          mkdir -p assets
          # Collect all release files
          for dir in release-artifacts/release-*; do
            if [ -d "$dir" ]; then
              # Move main archive
              mv $dir/*.{tar.gz,zip} assets/ 2>/dev/null || true
              # Move Linux packages
              mv $dir/*.deb assets/ 2>/dev/null || true
              mv $dir/*.rpm assets/ 2>/dev/null || true
              mv $dir/*.AppImage assets/ 2>/dev/null || true
              # Move macOS pkg packages
              mv $dir/*.pkg assets/ 2>/dev/null || true
              # Collect benchmark results
              cp $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
          done
          echo "Collected assets:"
          ls -la assets/
      # Combine step removed; use CHANGELOG.md directly for release notes

      - name: "Dry-run: print release notes (act only)"
        if: ${{ github.actor == 'nektos/act' }}
        shell: bash
        run: |
          echo "--- CHANGELOG.md (dry-run) ---"
          cat CHANGELOG.md

      - name: Create or update GitHub Release (draft, upload assets first)
        if: ${{ github.actor != 'nektos/act' && steps.asset_check.outputs.file_count != '0' }}
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.meta.outputs.tag }}
          name: ${{ steps.meta.outputs.release_name }}
          body_path: CHANGELOG.md
          files: assets/*
          draft: true
          prerelease: ${{ steps.meta.outputs.prerelease }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Publish GitHub Release (flip draft=false)
        if: ${{ github.actor != 'nektos/act' && steps.asset_check.outputs.file_count != '0' }}
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "Installing gh CLI to publish release" >&2
            type -p curl >/dev/null || sudo apt-get update
            sudo apt-get install -y gh >/dev/null 2>&1 || true
          fi
          TAG="${{ steps.meta.outputs.tag }}"
          # publish the release after assets are uploaded
          gh release edit "$TAG" --draft=false --title "${{ steps.meta.outputs.release_name }}" --notes-file CHANGELOG.md \
            ${{ steps.meta.outputs.prerelease == 'true' && '--prerelease' || '--latest' }}

      - name: List release assets (post-upload)
        if: ${{ github.actor != 'nektos/act' }}
        shell: bash
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "Installing gh CLI for asset listing" >&2
            type -p curl >/dev/null || sudo apt-get update
            sudo apt-get install -y gh >/dev/null 2>&1 || true
          fi
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Release assets for $TAG:" >&2
          gh release view "$TAG" --json assets --jq '.assets[].name' || echo "(Could not list assets)"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
