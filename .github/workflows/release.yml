name: Release

on:
  push:
    tags:
      - "v*"  # Stable releases triggered by version tags
  workflow_dispatch:
    inputs:
      channel:
        description: "Release channel (stable|weekly|nightly)"
        required: false
        default: "nightly"

permissions:
  contents: write

jobs:
  warm:
    name: Warm Conan & ccache (matrix)
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux-hosted
            runs_on: ubuntu-latest
            suffix: linux-x86_64
            hosted: true
          - os: macos-hosted-arm64
            runs_on: macos-15
            suffix: macos-arm64
            hosted: true
          - os: macos-hosted-x64
            runs_on: macos-15
            suffix: macos-x86_64
            hosted: true
    runs-on: ${{ matrix.runs_on }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Cache Conan packages (warm)
        id: cache_conan_warm
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.conan2/p
            ~/.conan2/r
            ~/.conan2/recipes
            ~/.conan2/metadata
            ~/.conan2/s
          key: warm-conan2-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conan.lock', 'conanfile.py', 'CMakePresets.json') }}
          restore-keys: |
            warm-conan2-${{ runner.os }}-${{ matrix.suffix }}-
            warm-conan2-${{ runner.os }}-
            conan2-${{ runner.os }}-
      - name: Cache ccache (warm)
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/ccache
            ~/.ccache
          key: warm-ccache-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conan.lock', 'conanfile.py', 'CMakePresets.json') }}
          restore-keys: |
            warm-ccache-${{ runner.os }}-${{ matrix.suffix }}-
            warm-ccache-${{ runner.os }}-
            ccache-${{ runner.os }}-
      - name: Warm summary
        shell: bash
        run: |
          echo "Conan cache hit: ${{ steps.cache_conan_warm.outputs.cache-hit }}" || true
          du -sh ~/.conan2/p 2>/dev/null || true
          du -sh ~/.cache/ccache 2>/dev/null || true

  build-release:
    name: Build and Package (matrix)
    needs: warm
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux-hosted
            runs_on: ubuntu-latest
            suffix: linux-x86_64
            packaging: tar
            build_packages: true
            cmake_args: ""
            hosted: true
          - os: macos-hosted-arm64
            runs_on: macos-15
            suffix: macos-arm64
            packaging: zip
            build_packages: false
            cmake_args: -DCMAKE_OSX_ARCHITECTURES=arm64
            hosted: true
          - os: macos-hosted-x64
            runs_on: macos-15
            suffix: macos-x86_64
            packaging: zip
            build_packages: false
            cmake_args: -DCMAKE_OSX_ARCHITECTURES="x86_64"
            hosted: true
    runs-on: ${{ matrix.runs_on }}
    env:
      STAGE_DIR: stage
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cache Conan packages (early)
        id: cache_conan_early
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.conan2/p
            ~/.conan2/r
            ~/.conan2/recipes
            ~/.conan2/metadata
            ~/.conan2/s
          # Use same key pattern as tests workflow for maximum cross-workflow reuse
          key: conan2-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conan.lock', 'conanfile.py', 'CMakePresets.json') }}
          restore-keys: |
            conan2-${{ runner.os }}-${{ matrix.suffix }}-
            conan2-${{ runner.os }}-
            conan-${{ runner.os }}-
      - name: Conan cache diagnostics (early)
        if: always()
        shell: bash
        run: |
          echo "Early cache hit: ${{ steps.cache_conan_early.outputs.cache-hit }}"
          for d in p r recipes metadata s; do
            if [ -d "$HOME/.conan2/$d" ]; then
              echo "Directory $d present: $(find $HOME/.conan2/$d -mindepth 1 -maxdepth 1 | wc -l | tr -d ' ') entries" || true
              du -sh $HOME/.conan2/$d 2>/dev/null || true
            else
              echo "Directory $d missing"
            fi
          done
      - name: Cache macOS build directory
        if: runner.os == 'macOS'
        uses: actions/cache@v4
        with:
          path: build/yams-release
          key: macos-build-${{ matrix.suffix }}-${{ hashFiles('CMakeLists.txt', 'CMakePresets.json') }}-${{ hashFiles('src/**', 'include/**') }}
          restore-keys: |
            macos-build-${{ matrix.suffix }}-

      - name: Cache ccache
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/ccache
            ~/.ccache
          key: ccache-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conan.lock', 'conanfile.py', 'CMakePresets.json') }}
          restore-keys: |
            ccache-${{ runner.os }}-${{ matrix.suffix }}-
            ccache-${{ runner.os }}-

      - name: Install optional system dependencies (Linux only)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          # Add rpm / fakeroot / dpkg-dev so CPack can emit .deb and .rpm packages
          sudo apt-get install -y --no-install-recommends \
            liburing-dev \
            libarchive-dev \
            libtag1-dev \
            ccache \
            rpm \
            fakeroot \
            dpkg-dev
          echo "Installed optional packages: liburing-dev libarchive-dev libtag1-dev ccache rpm fakeroot dpkg-dev"

      - name: Sanitize stdlib flags (macOS only)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # Remove any accidentally injected libstdc++ selections and force libc++
          for var in CXXFLAGS CFLAGS LDFLAGS; do
            current="${!var:-}"
            sanitized="$(echo "$current" | sed -E 's/-stdlib=libstdc\+\+//g') -stdlib=libc++"
            # Collapse whitespace
            sanitized="$(echo "$sanitized" | tr -s ' ')"
            echo "$var=$sanitized" >> "$GITHUB_ENV"
            printf '%s\n' "$var=$sanitized"
          done
          echo "Stdlib flags sanitized for macOS (forcing -stdlib=libc++)."

      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          # When schedule triggers, this contains the cron expression that matched
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            # Tie channel to the configured crons above
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          else
            # Fallback for workflow_run or any other event
            channel="stable"
          fi

          # Derive version and tag
          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
          elif [ "$channel" = "nightly" ]; then
            DATE="$(date -u +%Y%m%d)"
            VERSION="nightly-${DATE}"
            TAG_OUT="$VERSION"
          else # weekly
            YEAR="$(date -u +%G)"   # ISO week-numbering year
            WEEK="$(date -u +%V)"   # ISO week number 01-53
            VERSION="weekly-${YEAR}w${WEEK}"
            TAG_OUT="$VERSION"
          fi

          # Derive a strictly numeric semantic base version for packaging (DEB/RPM require this);
          # fall back to 0.0.0 if no tag history exists.
          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT"

      - name: Download CI benchmark artifacts (-yams, if available)
        if: github.event_name == 'workflow_run'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          workflow: ci.yml
          workflow_conclusion: success
          name: benchmark-results-${{ matrix.os }}-yams
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI benchmark artifacts (legacy -conan, fallback)
        if: github.event_name == 'workflow_run'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          workflow: ci.yml
          workflow_conclusion: success
          name: benchmark-results-${{ matrix.os }}-conan
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI coverage (if available)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          workflow: ci.yml
          workflow_conclusion: success
          name: coverage-report
          path: ci-artifacts/coverage
          if_no_artifact_found: warn


      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      # Hosted runners: install and configure Conan (self-hosted must already be configured)
      - name: Install Conan (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          pipx install conan 2>/dev/null || python3 -m pip install --upgrade conan || python -m pip install --upgrade conan || pip3 install --upgrade conan
          conan --version
          mkdir -p ~/.conan2
          # Best-effort: global.conf may not exist in repo for hosted macOS
          cp .conan/global.conf ~/.conan2/global.conf 2>/dev/null || true

      - name: Ensure build tools (cmake, ninja) for local runners/act
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set -euo pipefail
          need_modern_cmake() {
            if ! command -v cmake >/dev/null 2>&1; then
              return 0
            fi
            v=$(cmake --version | head -1 | sed -E 's/.* ([0-9]+)\.([0-9]+)\..*/\1.\2/')
            awk -v have="$v" 'BEGIN{ split(have,a,"."); if (a[1]>3 || (a[1]==3 && a[2]>=25)) exit 1; else exit 0 }'
          }

          add_user_bin_to_path() {
            if [ -n "${GITHUB_PATH:-}" ]; then
              echo "$HOME/.local/bin" >> "$GITHUB_PATH"
            else
              export PATH="$HOME/.local/bin:$PATH"
            fi
          }

          if need_modern_cmake; then
            echo "Installing modern CMake and Ninja via pip"
            python3 -m pip install --user --upgrade cmake 'ninja>=1.10' || python -m pip install --user --upgrade cmake 'ninja>=1.10'
            add_user_bin_to_path
            echo "cmake version: $(cmake --version | head -1)"
            echo "ninja version: $(ninja --version || true)"
          elif ! command -v ninja >/dev/null 2>&1; then
            echo "Installing Ninja via pip"
            python3 -m pip install --user --upgrade 'ninja>=1.10' || true
            add_user_bin_to_path
          else
            echo "cmake present: $(cmake --version | head -1)"
            echo "ninja present: $(ninja --version || true)"
          fi
          # Install ccache on macOS if missing
          if [ "$RUNNER_OS" = "macOS" ] && ! command -v ccache >/dev/null 2>&1; then
            brew install ccache || true
          fi

      - name: Setup ccache env
        shell: bash
        run: |
          echo "CCACHE_DIR=$HOME/.cache/ccache" >> $GITHUB_ENV
          echo "CCACHE_BASEDIR=$GITHUB_WORKSPACE" >> $GITHUB_ENV
          echo "CCACHE_COMPRESS=1" >> $GITHUB_ENV
          echo "CCACHE_MAXSIZE=700M" >> $GITHUB_ENV
          ccache -z 2>/dev/null || true

      - name: Setup Conan (hosted Linux/macOS)
        if: ${{ matrix.hosted  }}
        shell: bash
        run: |
          set -e
          conan profile detect --force
          echo "Conan detected default profile. A platform-specific profile (host-macos-apple-clang or host-linux-clang) will be applied explicitly later."

      - name: Detect clang version (log only)
        shell: bash
        run: |
          set -euo pipefail
          # Prefer clang++, fallback to clang
            if command -v clang++ >/dev/null 2>&1; then
              RAW_VER=$(clang++ --version | sed -n 's/.*version \([0-9][0-9]*\).*/\1/p' | head -1 || true)
            elif command -v clang >/dev/null 2>&1; then
              RAW_VER=$(clang --version | sed -n 's/.*version \([0-9][0-9]*\).*/\1/p' | head -1 || true)
            else
              RAW_VER=""
            fi
            if [ -z "$RAW_VER" ]; then
              echo "Could not auto-detect clang version; using profile defaults" >&2
            else
              echo "Detected clang major: $RAW_VER"
            fi

      - name: Check Conan (self-hosted sanity)
        if: ${{ !matrix.hosted }}
        shell: bash
        run: conan --version || echo "Conan is expected to be pre-installed and configured on self-hosted runners"

      # Hosted runners: clean corrupted cache if needed
      - name: Clean corrupted Conan cache if needed (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          if ! conan list "*" 2>/dev/null;
          then
            echo "Conan cache appears corrupted, cleaning locks and temp files..."
            conan cache clean --locks --temp 2>/dev/null || true
            echo "Conan cache locks/temp cleaned"
          fi

      # Release build for ALL targets
      - name: Configure and Build Release (Optimized)
        shell: bash
        run: |
          echo "Optimized release build for ${{ matrix.suffix }}"
          # Clean any existing build directory and presets to avoid duplicate preset issues
          rm -rf build/yams-release
          rm -f CMakeUserPresets.json
          # Select explicit platform profile (no mutation-in-place)
          if [ "$RUNNER_OS" = "macOS" ]; then
            HOST_PROFILE="./conan/profiles/host-macos-apple-clang"
            # Adjust architecture dynamically for universal runner matrix
            case "${{ matrix.suffix }}" in
              macos-arm64)
                sed -i '' -E 's/^arch=.*/arch=armv8/' "$HOST_PROFILE"
                ;;
              macos-x86_64)
                cp "$HOST_PROFILE" "$HOST_PROFILE.x86_64"
                sed -i '' -E 's/^arch=.*/arch=x86_64/' "$HOST_PROFILE.x86_64"
                HOST_PROFILE="$HOST_PROFILE.x86_64"
                ;;
            esac
          else
            HOST_PROFILE="./conan/profiles/host-linux-clang"
          fi
          BUILD_PROFILE="default"
          CONAN_ARGS="-of build/yams-release -pr:h=$HOST_PROFILE -pr:b=$BUILD_PROFILE -s build_type=Release -b missing"
          if [ "$RUNNER_OS" = "macOS" ]; then
            case "${{ matrix.suffix }}" in
              macos-arm64) CONAN_ARGS="$CONAN_ARGS -s:h arch=armv8" ;;
              macos-x86_64) CONAN_ARGS="$CONAN_ARGS -s:h arch=x86_64" ;;
            esac
          fi
          conan install . $CONAN_ARGS
          echo "--- Toolchain sanity (first toolchain file if present) ---"
          find build/yams-release -maxdepth 5 -name conan_toolchain.cmake -print -exec grep -E 'CMAKE_CXX_COMPILER' {} \; | head -20 || true
          cmake --preset yams-release \
            -DYAMS_BUILD_PROFILE=release \
            -DYAMS_VERSION="${{ steps.meta.outputs.version }}" \
            -DCMAKE_CXX_STANDARD=20 \
            -DCMAKE_INSTALL_PREFIX="$GITHUB_WORKSPACE/${{ env.STAGE_DIR }}" \
            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
            ${{ matrix.cmake_args}}
          cmake --build --preset yams-release --parallel
          echo "BUILD_DIR=build/yams-release" >> $GITHUB_ENV

      - name: ccache stats (post-build)
        shell: bash
        run: |
          ccache -s || echo "ccache stats unavailable"

      - name: Collect benchmark results
        shell: bash
        run: |
          mkdir -p "$BUILD_DIR/bench_results"
          # Collect from validation build (if Linux hosted ran validation)
          if [ -f "build/yams-release/bench_results.json" ]; then
            cp build/yams-release/bench_results.json "$BUILD_DIR/bench_results/"
            echo "Collected benchmark results from validation build"
          fi
          # Also check CI artifacts if available
          if [ -d "ci-artifacts/benchmarks" ] && [ "$(ls -A ci-artifacts/benchmarks/*.json 2>/dev/null)" ]; then
            cp ci-artifacts/benchmarks/*.json "$BUILD_DIR/bench_results/" || true
          fi

      - name: Install
        shell: bash
        run: |
          # Ensure BUILD_DIR is properly set
          if [ ! -d "$BUILD_DIR" ]; then
            echo "BUILD_DIR not found at $BUILD_DIR, checking for alternative..."
            if [ -d "build/yams-release" ]; then
              BUILD_DIR="build/yams-release"
              echo "Using BUILD_DIR: $BUILD_DIR"
              echo "BUILD_DIR=$BUILD_DIR" >> $GITHUB_ENV
            fi
          fi
          cmake --install "$BUILD_DIR" --config Release

      - name: Generate release summary
        shell: bash
        run: |
          SUMMARY_FILE="$BUILD_DIR/release_summary.md"
          echo "## Release Build Information (${{ steps.meta.outputs.version }})" > "$SUMMARY_FILE"
          echo "" >> "$SUMMARY_FILE"
          echo "**Platform:** ${{ matrix.suffix }}" >> "$SUMMARY_FILE"
          echo "**Build Type:** Release" >> "$SUMMARY_FILE"
          echo "**Channel:** ${{ steps.meta.outputs.channel }}" >> "$SUMMARY_FILE"

          # Only mention CI validation if we actually have CI artifacts
          if [ -d "ci-artifacts" ] && [ "$(ls -A ci-artifacts/ 2>/dev/null)" ]; then
            echo "**CI Status:** Tests and benchmarks from CI workflow" >> "$SUMMARY_FILE"
          fi
          echo "" >> "$SUMMARY_FILE"

          # Add coverage information if available (no python dependency)
          if [ -f "ci-artifacts/coverage/coverage.xml" ]; then
            echo "### Test Coverage" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            # Extract line-rate="0.8234" attribute and convert to percent with one decimal
            raw_rate=$(grep -Eo 'line-rate="[0-9.]+"' ci-artifacts/coverage/coverage.xml | head -1 | sed -E 's/.*="([0-9.]+)"/\1/' ) || raw_rate=""
            if [ -n "$raw_rate" ]; then
              # Use awk for safe float multiplication & formatting
              coverage_pct=$(awk -v r="$raw_rate" 'BEGIN{ printf("%.1f%%", r*100) }')
            else
              coverage_pct="N/A"
            fi
            echo "**Line Coverage:** $coverage_pct" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
          fi

          # Add benchmark results if available from CI or validation (jq preferred, fallback to grep)
          if [ -d "$BUILD_DIR/bench_results" ] && ls "$BUILD_DIR/bench_results"/*.json >/dev/null 2>&1; then
            echo "### Performance Metrics" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            echo "| Benchmark | Time (ns/op) | CPU (ns/op) | Memory |" >> "$SUMMARY_FILE"
            echo "|-----------|--------------|-------------|--------|" >> "$SUMMARY_FILE"
            if command -v jq >/dev/null 2>&1; then
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                jq -r '.benchmarks[]? | "| \(.name // \"Unknown\") | \(.real_time // 0 | floor) | \(.cpu_time // 0 | floor) | \n"' "$json_file" 2>/dev/null | while IFS= read -r line; do
                  name=$(echo "$line" | cut -d'|' -f2 | sed 's/^ *//;s/ *$//')
                  rtime=$(echo "$line" | cut -d'|' -f3 | tr -d ' ')
                  ctime=$(echo "$line" | cut -d'|' -f4 | tr -d ' ')
                  # Derive memory throughput if bytes_per_second present
                  mem=$(jq -r --arg n "$name" '.benchmarks[]? | select(.name==$n) | if (.bytes_per_second // 0) > 0 then ((.bytes_per_second/1024/1024)|tostring)+" MB/s" else (if (.items_per_second // 0) > 0 then ((.items_per_second)|tostring)+" ops/s" else "N/A" end) end' "$json_file" 2>/dev/null)
                  [ -z "$mem" ] && mem="N/A"
                  echo "| $name | $rtime | $ctime | $mem |" >> "$SUMMARY_FILE"
                done
              done
            else
              # Minimal fallback: grep fields (less robust)
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                grep '"name"' "$json_file" | sed -E 's/.*"name": *"([^"]+)".*/| \1 | ? | ? | N/A |/' >> "$SUMMARY_FILE" || true
              done
            fi
            echo "" >> "$SUMMARY_FILE"
          fi

          echo "Generated release summary at: $SUMMARY_FILE"
          cat "$SUMMARY_FILE"

      - name: Package
        shell: bash
        run: |
          cd "$GITHUB_WORKSPACE/${{ env.STAGE_DIR }}"
          VERSION="${{ steps.meta.outputs.version }}"
          SUFFIX="${{ matrix.suffix }}"
          OUTDIR="$GITHUB_WORKSPACE"
          if [ "${{ matrix.packaging }}" = "zip" ]; then
            ASSET="yams-${VERSION}-${SUFFIX}.zip"
            zip -r "$OUTDIR/$ASSET" .
          else
            ASSET="yams-${VERSION}-${SUFFIX}.tar.gz"
            tar czf "$OUTDIR/$ASSET" .
          fi
          echo "ASSET_PATH=$OUTDIR/$ASSET" >> "$GITHUB_ENV"
          echo "Created asset: $OUTDIR/$ASSET"

      - name: Build Linux packages (DEB/RPM)
        if: matrix.build_packages == true && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          cd "$BUILD_DIR"
          DISPLAY_VERSION="${{ steps.meta.outputs.version }}"
          PKG_VERSION="${{ steps.meta.outputs.base_version }}"   # numeric semantic for DEB/RPM metadata

          echo "Packaging with DISPLAY_VERSION=$DISPLAY_VERSION (package metadata version=$PKG_VERSION)"

          # Generate DEB package (use numeric version for control file)
          cpack -G DEB \
            -D CPACK_PACKAGE_VERSION="${PKG_VERSION}" \
            -D CPACK_DEBIAN_PACKAGE_MAINTAINER="Trevon <git@trevon.dev>" \
            -D CPACK_PACKAGE_CONTACT="Trevon <git@trevon.dev>" || echo "CPack DEB generation failed"
          DEB_FILE=$(ls *.deb 2>/dev/null | head -1 || true)
          if [ -n "$DEB_FILE" ]; then
            TARGET_DEB="yams-${DISPLAY_VERSION}-linux-x86_64.deb"
            mv "$DEB_FILE" "$GITHUB_WORKSPACE/$TARGET_DEB"
            echo "Created DEB package: $TARGET_DEB"
          else
            echo "WARNING: No .deb produced (possibly due to CPack config or empty install set)" >&2
          fi

          # Generate RPM package (only if rpmbuild exists)
          if command -v rpmbuild >/dev/null 2>&1; then
            cpack -G RPM \
              -D CPACK_PACKAGE_VERSION="${PKG_VERSION}" \
              -D CPACK_PACKAGE_CONTACT="Trevon <git@trevon.dev>" || echo "CPack RPM generation failed"
            RPM_FILE=$(ls *.rpm 2>/dev/null | head -1 || true)
            if [ -n "$RPM_FILE" ]; then
              TARGET_RPM="yams-${DISPLAY_VERSION}-linux-x86_64.rpm"
              mv "$RPM_FILE" "$GITHUB_WORKSPACE/$TARGET_RPM"
              echo "Created RPM package: $TARGET_RPM"
            else
              echo "WARNING: No .rpm produced" >&2
            fi
          else
            echo "rpmbuild not found, skipping RPM generation"
          fi
          # Generate AppImage if appimage-builder is available
          if command -v appimage-builder >/dev/null 2>&1; then
            cd "$GITHUB_WORKSPACE"
            cp packaging/appimage/AppImageBuilder.yml .
            export YAMS_VERSION="${DISPLAY_VERSION}"
            appimage-builder --skip-tests || echo "AppImage build failed, skipping"
            APPIMAGE_FILE=$(ls YAMS-*.AppImage 2>/dev/null | head -1)
            if [ -n "$APPIMAGE_FILE" ]; then
              mv "$APPIMAGE_FILE" "yams-${DISPLAY_VERSION}-x86_64.AppImage"
              echo "Created AppImage: yams-${DISPLAY_VERSION}-x86_64.AppImage"
            fi
          else
            echo "appimage-builder not found, skipping AppImage generation"
          fi

      - name: Combine release notes with build information (stable only)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          COMBINED_NOTES="$BUILD_DIR/combined_release_notes.md"
          echo "${{ steps.changelog.outputs.release_notes }}" > "$COMBINED_NOTES"
          echo "" >> "$COMBINED_NOTES"

          # Add release summary if it exists
          if [ -f "$BUILD_DIR/release_summary.md" ]; then
            cat "$BUILD_DIR/release_summary.md" >> "$COMBINED_NOTES"
          fi

          echo "Combined release notes:"
          cat "$COMBINED_NOTES"

      - name: Publish matrix.json (expected platform count)
        if: matrix.os == 'linux-hosted'
        shell: bash
        run: |
          # Only generate once (linux-hosted) to avoid artifact name collision across matrix entries.
          # Update to reflect current matrix total (3 platforms)
          echo '{"total": 3}' > matrix.json

      - name: Upload matrix metadata
        if: matrix.os == 'linux-hosted'
        uses: actions/upload-artifact@v4
        with:
          name: matrix-meta
          path: matrix.json
          retention-days: 1

      - name: Upload Release Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ matrix.suffix }}-files${{ github.run_attempt > 1 && format('-a{0}', github.run_attempt) || '' }}
          path: |
            yams-*.tar.gz
            yams-*.zip
            ${{ env.BUILD_DIR }}/release_summary.md
            ${{ env.BUILD_DIR }}/bench_results/*.json
            yams-*.deb
            yams-*.rpm
            yams-*.AppImage
            yams-*.pkg
          retention-days: 1

      - name: Verify Linux package artifacts
        if: matrix.os == 'linux-hosted'
        shell: bash
        run: |
          set -euo pipefail
          echo "Verifying expected Linux package artifacts (DEB/RPM)"
          ls -1 yams-*linux-x86_64.deb 2>/dev/null || { echo "ERROR: Missing .deb package" >&2; exit 1; }
          if command -v rpmbuild >/dev/null 2>&1; then
            ls -1 yams-*linux-x86_64.rpm 2>/dev/null || { echo "ERROR: Missing .rpm package" >&2; exit 1; }
          else
            echo "rpmbuild unavailable; RPM check skipped" >&2
          fi
          echo "Linux package verification complete"

  create-release:
    name: Create GitHub Release
    needs: build-release
    runs-on: ubuntu-latest
    # Run unconditionally; dynamic threshold enforced inside the job
    if: always() && !cancelled()
    permissions:
      contents: write
      actions: read
    steps:
      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          else
            channel="stable"
          fi

          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
          elif [ "$channel" = "nightly" ]; then
            DATE="$(date -u +%Y%m%d)"
            VERSION="nightly-${DATE}"
            TAG_OUT="$VERSION"
          else
            YEAR="$(date -u +%G)"
            WEEK="$(date -u +%V)"
            VERSION="weekly-${YEAR}w${WEEK}"
            TAG_OUT="$VERSION"
          fi

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          # Derive numeric base version (used for packaging metadata). Fallback 0.0.0
          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT"

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts
          pattern: "*"

      - name: List downloaded artifacts (debug)
        shell: bash
        run: |
          echo "Downloaded artifact directories:" >&2
          find release-artifacts -maxdepth 2 -type f -printf '%P\n' 2>/dev/null || true

      - name: Collect assets into staging directory
        shell: bash
        run: |
          set -euo pipefail
          rm -rf assets || true
          mkdir -p assets
          # Collect all per-platform release artifacts
          for dir in release-artifacts/release-*; do
            [ -d "$dir" ] || continue
            # Archives
            cp -v $dir/*.tar.gz assets/ 2>/dev/null || true
            cp -v $dir/*.zip assets/ 2>/dev/null || true
            # Packages
            cp -v $dir/*.deb assets/ 2>/dev/null || true
            cp -v $dir/*.rpm assets/ 2>/dev/null || true
            cp -v $dir/*.AppImage assets/ 2>/dev/null || true
            # Summaries & bench json
            if [ -d "$dir/bench_results" ]; then
              cp -v $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
            if [ -f "$dir/release_summary.md" ]; then
              cp -v "$dir/release_summary.md" "assets/release_summary-$(basename "$dir").md" 2>/dev/null || true
            fi
          done
          echo "Final assets content:" >&2
          ls -al assets >&2 || true

      - name: Generate checksums
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "Generating SHA256SUMS for release assets" >&2
          # Exclude bench JSON and summaries from checksum manifest (only distributable binaries)
          ls -1 | grep -E '\.(tar.gz|zip|deb|rpm|AppImage|pkg)$' | while read -r f; do
            sha256sum "$f" >> SHA256SUMS
          done
          sort -o SHA256SUMS SHA256SUMS
          echo "Created checksum manifest:" >&2
          cat SHA256SUMS >&2

      - name: (Optional) Import GPG key and sign checksums
        if: env.GPG_PRIVATE_KEY && env.GPG_PRIVATE_KEY != ''
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY || '' }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE || '' }}
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "GPG key present: generating detached signature for SHA256SUMS" >&2
          echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --import
          gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --detach-sign --armor -o SHA256SUMS.asc SHA256SUMS
          echo "Signature generated (SHA256SUMS.asc)" >&2

      - name: Verify asset set
        id: asset_check
        shell: bash
        run: |
          COUNT=$(find assets -type f | wc -l | tr -d ' ')
          echo "Discovered $COUNT asset files" >&2
          echo "file_count=$COUNT" >> $GITHUB_OUTPUT
          if [ "$COUNT" -eq 0 ]; then
            echo "ERROR: No asset files assembled for release." >&2
            exit 1
          fi

      - name: Generate Homebrew formula (stable only)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          TAG="${{ steps.meta.outputs.tag }}"
          VERSION="${{ steps.meta.outputs.version }}"
          FORMULA_DIR="homebrew"
          mkdir -p "$FORMULA_DIR"
          ARCHIVE_URL="https://github.com/${{ github.repository }}/archive/refs/tags/${TAG}.tar.gz"
          echo "Downloading source tarball: $ARCHIVE_URL" >&2
          TARBALL="${TAG}.tar.gz"
          curl -Ls -o "$TARBALL" "$ARCHIVE_URL"
          SHA256=$(shasum -a 256 "$TARBALL" | awk '{print $1}')
          echo "Computed sha256: $SHA256" >&2
          TEMPLATE_PATH="packaging/homebrew/yams.rb"
          if [ ! -f "$TEMPLATE_PATH" ]; then
            echo "ERROR: Homebrew template not found at $TEMPLATE_PATH" >&2
            exit 1
          fi
          OUT_FORMULA="$FORMULA_DIR/yams.rb"
          # Update url & sha256 lines (simple sed in-place replacement)
          sed \
            -e "s|^  url \".*\"|  url \"$ARCHIVE_URL\"|" \
            -e "s|^  sha256 \".*\"|  sha256 \"$SHA256\"|" \
            "$TEMPLATE_PATH" > "$OUT_FORMULA"
          echo "Updated formula at $OUT_FORMULA:" >&2
          grep -E 'url "|sha256 "' "$OUT_FORMULA" >&2 || true
          # Create quick install instructions file
          cat > "$FORMULA_DIR/README.txt" <<EOF
          Homebrew formula generated for YAMS $VERSION
          To use without a tap:
            brew install --build-from-source $OUT_FORMULA

          Recommended (create a tap repository and place yams.rb there), e.g.:
            1. Create repo: github.com/<you>/homebrew-yams
            2. Add this formula as Formula/yams.rb
            3. Users run: brew install <you>/yams/yams
          EOF

      - name: Upload Homebrew formula artifact
        if: steps.meta.outputs.channel == 'stable'
        uses: actions/upload-artifact@v4
        with:
          name: homebrew-formula
          path: homebrew/
          retention-days: 7

      - name: Open Homebrew formula update PR (stable only)
        if: steps.meta.outputs.channel == 'stable' && github.actor != 'nektos/act'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          BRANCH="update/formula-v${VERSION}"
          # Ensure we are on main for branch base
          git checkout main || git checkout -B main
          git pull --ff-only origin main || true
          # Create/update branch
          git checkout -B "$BRANCH"
          # Copy generated formula into repository location (replace placeholder version/sha)
          if [ -f homebrew/yams.rb ]; then
            cp homebrew/yams.rb packaging/homebrew/yams.rb
          else
            echo "Generated formula not found; aborting PR step" >&2
            exit 0
          fi
          if git diff --quiet -- packaging/homebrew/yams.rb; then
            echo "Formula unchanged; skipping PR creation"
            exit 0
          fi
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
          git add packaging/homebrew/yams.rb
          git commit -m "chore(homebrew): update formula to v${VERSION}" || true
          git push --set-upstream origin "$BRANCH" || {
            echo "Push failed (possibly permissions). Exiting." >&2
            exit 0
          }
          if command -v gh >/dev/null 2>&1; then
            gh pr create \
              --title "chore(homebrew): update formula to v${VERSION}" \
              --body "Automated Homebrew formula update for YAMS ${VERSION}.\nSource tag: v${VERSION}" \
              --base main \
              --head "$BRANCH" || echo "PR creation skipped (already exists?)"
          else
            echo "gh CLI not installed; PR not created (branch pushed: $BRANCH)" >&2
          fi

      - name: Build APT repository metadata (stable only, linux .deb present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          # Require at least one .deb in assets
          if ! ls assets/*.deb >/dev/null 2>&1; then
            echo "No .deb found; skipping APT repo generation" >&2
            exit 0
          fi
          BASE_VERSION="${{ steps.meta.outputs.base_version }}"
          REPO_ROOT="aptrepo"
          POOL_DIR="$REPO_ROOT/pool/main/y/yams"
          DIST=stable
          COMPONENT=main
          ARCH=amd64
          mkdir -p "$POOL_DIR" "$REPO_ROOT/dists/$DIST/$COMPONENT/binary-$ARCH"
          # Copy & normalize deb naming (yams_<version>_amd64.deb)
          for deb in assets/*.deb; do
            cp "$deb" "$POOL_DIR/$(echo "$deb" | sed -E "s|.*yams-([^-]+)-linux-x86_64\.deb|yams_${BASE_VERSION}_amd64.deb|")" || true
          done
          # Install dpkg-dev if missing (for dpkg-scanpackages)
          if ! command -v dpkg-scanpackages >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y dpkg-dev
          fi
          pushd "$REPO_ROOT" >/dev/null
          dpkg-scanpackages --multiversion pool > dists/$DIST/$COMPONENT/binary-$ARCH/Packages
          gzip -c dists/$DIST/$COMPONENT/binary-$ARCH/Packages > dists/$DIST/$COMPONENT/binary-$ARCH/Packages.gz
          cat > dists/$DIST/Release <<REL
          Origin: YAMS
          Label: YAMS
          Suite: $DIST
          Codename: $DIST
          Architectures: $ARCH
          Components: $COMPONENT
          Description: YAMS APT repository
          REL
          # Optional GPG signing if secret present
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes -abs -o dists/$DIST/Release.gpg dists/$DIST/Release
            gpg --batch --yes --clearsign -o dists/$DIST/InRelease dists/$DIST/Release
          fi
          popd >/dev/null
          tree "$REPO_ROOT" || find "$REPO_ROOT" -maxdepth 4 -type f -print
          cat > "$REPO_ROOT/USAGE.txt" <<EOF
          Add this APT repo (unsigned example):
            curl -fsSL https://${{ github.repository_owner }}.pages.dev/aptrepo/gpg.key -o /usr/share/keyrings/yams.gpg   # (If you later publish a key)
            echo "deb [signed-by=/usr/share/keyrings/yams.gpg] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams

          If unsigned (temporary/testing):
            echo "deb [trusted=yes] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams
          EOF

      - name: Upload APT repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: apt-repo
          path: aptrepo/
          retention-days: 7

      - name: Build YUM repository metadata (stable only, rpm present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          if ! ls assets/*.rpm >/dev/null 2>&1; then
            echo "No .rpm found; skipping YUM repo generation" >&2
            exit 0
          fi
          YUM_ROOT="yumrepo"
          mkdir -p "$YUM_ROOT"
          cp assets/*.rpm "$YUM_ROOT/" 2>/dev/null || true
          # Install createrepo_c if needed
          if ! command -v createrepo_c >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y createrepo-c
          fi
            
          createrepo_c "$YUM_ROOT"
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes --detach-sign --armor -o "$YUM_ROOT/repodata/repomd.xml.asc" "$YUM_ROOT/repodata/repomd.xml"
          fi
          cat > "$YUM_ROOT/USAGE.txt" <<EOF
          Add YUM/DNF repo (unsigned example):
            sudo tee /etc/yum.repos.d/yams.repo <<'REPO'
            [yams]
            name=YAMS Repository
            baseurl=https://${{ github.repository_owner }}.pages.dev/yumrepo/
            enabled=1
            gpgcheck=0
            repo_gpgcheck=0
            REPO

          Then install:
            sudo dnf makecache || sudo yum makecache
            sudo dnf install yams || sudo yum install yams

          (Enable gpgcheck once you publish a key and sign RPMs/repodata.)
          EOF

      - name: Upload YUM repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: yum-repo
          path: yumrepo/
          retention-days: 7

      - name: Generate latest manifest (latest.json)
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAG="${{ steps.meta.outputs.tag }}"
            CHANNEL="${{ steps.meta.outputs.channel }}"
          DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          mkdir -p assets
          cd assets
          if [ ! -f SHA256SUMS ]; then
            echo "Missing SHA256SUMS file in assets/; cannot build manifest" >&2
            ls -al >&2 || true
            exit 1
          fi
          # Build assets array JSON using awk (avoid jq dependency); trim trailing comma
          ASSETS_JSON=$(awk '{printf "{\"name\":\"%s\",\"sha256\":\"%s\"},", $2, $1}' SHA256SUMS | sed 's/,$//')
          cat > latest.json <<LJSON
          {
            "version": "${VERSION}",
            "tag": "${TAG}",
            "channel": "${CHANNEL}",
            "published_at": "${DATE}",
            "assets": [${ASSETS_JSON}]
          }
          LJSON
          echo "latest.json manifest (assets/latest.json):" >&2
          sed 's/^/  /' latest.json >&2

      - name: Check existing release (stable only)
        id: existing_release
        shell: bash
        run: |
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Checking if release $TAG already exists" >&2
          if command -v gh >/dev/null 2>&1; then
            if gh release view "$TAG" >/dev/null 2>&1; then
              echo "exists=true" >> $GITHUB_OUTPUT
            else
              echo "exists=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "gh CLI not installed; skipping existence check" >&2
            echo "exists=unknown" >> $GITHUB_OUTPUT
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Check job completion status
        id: check-status
        shell: bash
        run: |
          # Discover expected platforms from matrix job names in this run
          JOBS_JSON=$(curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                           -H "Accept: application/vnd.github.v3+json" \
                           -s "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100")
          # Extract unique platform identifiers from "Build and Release (<platform>)" job names
          EXPECTED_PLATFORMS=$(echo "$JOBS_JSON" | sed -n 's/.*"name"[[:space:]]*:[[:space:]]*"\(Build and Release ([^\"]*)\)".*/\1/p' | sed -n 's/Build and Release (\(.*\))/\1/p' | sort -u)
          TOTAL_EXPECTED=$(echo "$EXPECTED_PLATFORMS" | grep -c . || true)

          # Count successful artifacts from downloaded files (release-*)
          if [ -d "release-artifacts" ]; then
            # Count per-platform artifact directories (robust against file/dir listing quirks)
            SUCCESS_COUNT=$(find "release-artifacts" -mindepth 1 -maxdepth 1 -type d -name 'release-*' 2>/dev/null | grep -c . || true)
          else
            SUCCESS_COUNT=0
          fi

          # Determine expected builds:
          # 1) Prefer matrix.json (if provided)
          # 2) Otherwise, fall back to number of artifact groups downloaded
          if [ -f "release-artifacts/matrix.json" ]; then
            TOTAL_EXPECTED=$(cat "release-artifacts/matrix.json" | tr -d '\r' | grep -Eo '"total"[[:space:]]*:[[:space:]]*[0-9]+' | grep -Eo '[0-9]+' | head -1)
          fi
          if [ -z "$TOTAL_EXPECTED" ] || [ "$TOTAL_EXPECTED" -eq 0 ]; then
            TOTAL_EXPECTED="$SUCCESS_COUNT"
          fi

          # Compute dynamic threshold = ceil(TOTAL_EXPECTED / 2)
          THRESHOLD=$(( (TOTAL_EXPECTED + 1) / 2 ))

          echo "Successful builds: $SUCCESS_COUNT out of $TOTAL_EXPECTED (threshold: $THRESHOLD)"

          if [ "$SUCCESS_COUNT" -lt "$THRESHOLD" ]; then
            echo "ERROR: Need at least $THRESHOLD successful builds to create release (out of $TOTAL_EXPECTED expected)"
            exit 1
          fi

          echo "success_count=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "total_expected=$TOTAL_EXPECTED" >> $GITHUB_OUTPUT
          echo "threshold=$THRESHOLD" >> $GITHUB_OUTPUT

      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      - name: Extract grouped changelogs for minor version (stable only)
        id: grouped-changelog
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          # Extract minor version from current tag
          CURRENT_VERSION="${{ steps.meta.outputs.version }}"
          MINOR_VERSION=$(echo "$CURRENT_VERSION" | sed -E 's/^v?([0-9]+\.[0-9]+).*/\1/')

          echo "Current version: $CURRENT_VERSION"
          echo "Extracting all changes for minor version: $MINOR_VERSION"

          # Create grouped changelog file
          GROUPED_FILE="grouped_changelog_${MINOR_VERSION}.md"

          # Extract all entries for this minor version from CHANGELOG.md
          echo "# Release Notes for v${MINOR_VERSION}.x Series" > "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"
          echo "This release is part of the v${MINOR_VERSION}.x series. Below are all changes in this series:" >> "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"

          # Parse CHANGELOG.md and extract all sections matching the minor version
          awk -v minor="$MINOR_VERSION" '
            /^## \[v?[0-9]+\.[0-9]+\.[0-9]+/ {
              version_str = $2
              gsub(/\ \[v?/, "", version_str)
              gsub(/\ /, "", version_str)
              split(version_str, version_parts, ".")
              version_minor = version_parts[1] "." version_parts[2]

              if (version_minor == minor) {
                in_section = 1
                print $0
                next
              } else {
                in_section = 0
              }
            }
            /^## \[/ && in_section { in_section = 0 }
            in_section { print }
          ' CHANGELOG.md >> "$GROUPED_FILE"

          # Store path for later use
          echo "grouped_changelog_file=$GROUPED_FILE" >> $GITHUB_OUTPUT
          echo "minor_version=$MINOR_VERSION" >> $GITHUB_OUTPUT

      - name: Prepare release assets
        shell: bash
        run: |
          mkdir -p assets
          # Collect all release files
          for dir in release-artifacts/release-*;
          do
            if [ -d "$dir" ]; then
              # Move main archive
              mv $dir/*.{tar.gz,zip} assets/ 2>/dev/null || true
              # Move Linux packages
              mv $dir/*.deb assets/ 2>/dev/null || true
              mv $dir/*.rpm assets/ 2>/dev/null || true
              mv $dir/*.AppImage assets/ 2>/dev/null || true
              # Move macOS pkg packages
              mv $dir/*.pkg assets/ 2>/dev/null || true
              # Collect benchmark results
              cp $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
          done
          echo "Collected assets:"
          ls -la assets/
      - name: Combine release notes
        shell: bash
        run: |
          COMBINED_NOTES="combined_release_notes.md"

          if [ "${{ steps.meta.outputs.channel }}" = "stable" ]; then
            echo "# YAMS ${{ steps.meta.outputs.version }}" > "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"
            echo "${{ steps.changelog.outputs.release_notes }}" >> "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"

            # Add platform build status
            echo "## Platform Builds" >> "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"
            echo "Successfully built for ${{ steps.check-status.outputs.success_count }} out of ${{ steps.check-status.outputs.total_expected }} platforms:" >> "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"

            # Add summaries from each platform
            for summary in release-artifacts/release-*/release_summary.md;
            do
              if [ -f "$summary" ]; then
                platform=$(basename $(dirname "$summary") | sed 's/release-//')
                echo "### ✅ $platform" >> "$COMBINED_NOTES"
                tail -n +2 "$summary" >> "$COMBINED_NOTES"
                echo "" >> "$COMBINED_NOTES"
              fi
            done

            # List missing platforms if any
            if [ "${{ steps.check-status.outputs.success_count }}" -lt "3" ]; then
              echo "### ⚠️ Missing Platforms" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              echo "Some platforms failed to build. They may be added in a future patch release." >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
            fi

            # Add series changelog if not a patch 0 release
            PATCH_VERSION=$(echo "${{ steps.meta.outputs.version }}" | sed -E 's/^v?[0-9]+\.[0-9]+\.([0-9]+).*/\1/')
            if [ "$PATCH_VERSION" != "0" ]; then
              echo "---" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              echo "## All Changes in v${{ steps.grouped-changelog.outputs.minor_version }}.x Series" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              echo "<details>" >> "$COMBINED_NOTES"
              echo "<summary>Click to expand full series changelog</summary>" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              # Include grouped changelog content
              if [ -f "${{ steps.grouped-changelog.outputs.grouped_changelog_file }}" ]; then
                tail -n +4 "${{ steps.grouped-changelog.outputs.grouped_changelog_file }}" >> "$COMBINED_NOTES"
              fi
              echo "" >> "$COMBINED_NOTES"
              echo "</details>" >> "$COMBINED_NOTES"
            fi
          else
            # Nightly/Weekly: generate minimal, automatic notes with commit log since last tag
            echo "# YAMS ${{ steps.meta.outputs.version }}" > "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"
            echo "This is an automated ${{ steps.meta.outputs.channel }} build." >> "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"
            PREV_TAG="$(git describe --tags --abbrev=0 2>/dev/null || true)"
            if [ -n "$PREV_TAG" ]; then
              echo "## Changes since $PREV_TAG" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              git log --pretty=format:"- %h %s (%an)" "${PREV_TAG}..HEAD" >> "$COMBINED_NOTES" || true
            else
              echo "## Recent changes" >> "$COMBINED_NOTES"
              echo "" >> "$COMBINED_NOTES"
              git log -n 50 --pretty=format:"- %h %s (%an)" >> "$COMBINED_NOTES" || true
            fi
            echo "" >> "$COMBINED_NOTES"
            echo "## Platform Builds" >> "$COMBINED_NOTES"
            echo "" >> "$COMBINED_NOTES"
            echo "Successfully built for ${{ steps.check-status.outputs.success_count }} out of ${{ steps.check-status.outputs.total_expected }} platforms." >> "$COMBINED_NOTES"
          fi

      - name: "Dry-run: print release notes (act only)"
        if: ${{ github.actor == 'nektos/act' }}
        shell: bash
        run: |
          echo "--- Combined Release Notes (dry-run) ---"
          cat combined_release_notes.md

      - name: Create or update GitHub Release
        if: ${{ github.actor != 'nektos/act' && steps.asset_check.outputs.file_count != '0' }}
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.meta.outputs.tag }}
          name: YAMS ${{ steps.meta.outputs.version }}
          body_path: combined_release_notes.md
          files: assets/*
          draft: false
          prerelease: ${{ steps.meta.outputs.prerelease }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: List release assets (post-upload)
        if: ${{ github.actor != 'nektos/act' }}
        shell: bash
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "Installing gh CLI for asset listing" >&2
            type -p curl >/dev/null || sudo apt-get update
            sudo apt-get install -y gh >/dev/null 2>&1 || true
          fi
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Release assets for $TAG:" >&2
          gh release view "$TAG" --json assets --jq '.assets[].name' || echo "(Could not list assets)"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
