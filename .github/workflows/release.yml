# yamllint disable rule:line-length
name: Release

'on':
  push:
    tags:
      - "v*"  # Stable releases triggered by version tags
  workflow_dispatch:
    inputs:
      channel:
        description: "Release channel (stable|weekly|nightly)"
        required: false
        default: "nightly"
      upload_r2:
        description: "Also upload built assets to Cloudflare R2 via Wrangler"
        required: false
        default: "false"
      fast_mode:
        description: "Skip packaging & verification steps (speed up local / act runs)"
        required: false
        default: "false"
      macos_only:
        description: "Limit matrix to macOS variants only (skip linux-hosted)"
        required: false
        default: "false"
  workflow_run:
    workflows:
      - Tests
    branches:
      - main
    types:
      - completed

permissions:
  contents: write

jobs:
  check-commits:
    name: Check for new commits (nightly/workflow_run only)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success'
    outputs:
      has_new_commits: ${{ steps.check.outputs.has_new_commits }}
      last_release_sha: ${{ steps.check.outputs.last_release_sha }}
    steps:
      - name: Check if there are new commits since last nightly release
        id: check
        shell: bash
        run: |
          # Get the latest nightly release
          LATEST_NIGHTLY=$(gh api \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/repos/${{ github.repository }}/releases" \
            --jq '.[] | select(.tag_name | startswith("nightly-")) | .tag_name' | head -1)
          
          if [ -z "$LATEST_NIGHTLY" ]; then
            echo "No previous nightly release found, will create one"
            echo "has_new_commits=true" >> $GITHUB_OUTPUT
            echo "last_release_sha=none" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Get the commit SHA of the last nightly
          LAST_SHA=$(gh api \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/repos/${{ github.repository }}/git/ref/tags/$LATEST_NIGHTLY" \
            --jq '.object.sha' || echo "")
          
          echo "last_release_sha=$LAST_SHA" >> $GITHUB_OUTPUT
          
          # Get current main HEAD
          CURRENT_SHA=$(gh api \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/repos/${{ github.repository }}/git/ref/heads/main" \
            --jq '.object.sha')
          
          if [ "$LAST_SHA" != "$CURRENT_SHA" ]; then
            # Count commits between last nightly and current main
            COMMITS=$(gh api \
              -H "Accept: application/vnd.github+json" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              "/repos/${{ github.repository }}/compare/${LAST_SHA}...${CURRENT_SHA}" \
              --jq '.total_commits' || echo "1")
            
            echo "has_new_commits=true" >> $GITHUB_OUTPUT
            echo "Found $COMMITS new commit(s) since last nightly ($LATEST_NIGHTLY)"
          else
            echo "has_new_commits=false" >> $GITHUB_OUTPUT
            echo "No new commits since last nightly release ($LATEST_NIGHTLY), skipping"
          fi
        env:
          GH_TOKEN: ${{ github.token }}

  warm:
    needs: [check-commits]
    if: |
      always() &&
      (needs.check-commits.result == 'skipped' || 
       needs.check-commits.outputs.has_new_commits == 'true' ||
       github.event_name == 'push' ||
       github.event_name == 'workflow_dispatch')
    uses: ./.github/workflows/matrix-warm.yml
    with:
      build_type: Release
      enable_onnx: false

  build-release:
    name: Build and Package (matrix)
    needs: warm
    if: |
      always() &&
      (needs.warm.result == 'success' || needs.warm.result == 'skipped')
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux-hosted
            runs_on: ubuntu-24.04
            suffix: linux-x86_64
            packaging: tar
            build_packages: true
            meson_args: ""
            hosted: true
          - os: linux-hosted-arm64
            runs_on: ubuntu-24.04-arm
            suffix: linux-arm64
            packaging: tar
            build_packages: true
            meson_args: ""
            hosted: true
          - os: macos-hosted-arm64
            runs_on: macos-15
            suffix: macos-arm64
            packaging: zip
            build_packages: false
            meson_args: "" # arch via profile edit
            hosted: true
          - os: macos-hosted-x64
            runs_on: macos-15
            suffix: macos-x86_64
            packaging: zip
            build_packages: false
            meson_args: ""
            hosted: true
          - os: windows-hosted
            runs_on: windows-latest
            suffix: windows-x86_64
            packaging: msi
            build_packages: true
            meson_args: ""
            hosted: true
    runs-on: ${{ matrix.runs_on }}
    env:
      STAGE_DIR: stage
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: false
      - name: Skip non-linux entries under act (build)
        if: github.actor == 'nektos/act' && matrix.os != 'linux-hosted'
        shell: bash
        run: |
          echo "Skipping build-release job steps for ${{ matrix.os }} under act"
          exit 0
      - name: Skip linux-hosted when macos_only=true
        if: inputs.macos_only == 'true' && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          echo "macos_only=true: skipping linux-hosted build-release job entry"
          exit 0
      - name: Verify runner architecture (act diagnostics)
        if: github.actor == 'nektos/act' && matrix.os == 'linux-hosted'
        shell: bash
        run: |
          set -euo pipefail
          ACT_UNAME="$(uname -m || true)"
          echo "Detected uname -m: ${ACT_UNAME}"
          if [ "${ACT_UNAME}" != "x86_64" ]; then
            echo "ERROR: Non-x86_64 architecture detected under act: ${ACT_UNAME}" >&2
            echo "cpuinfo (and other x86-specific code) will not build on this architecture." >&2
            echo "Re-run forcing amd64 containers, e.g.:" >&2
            echo "  act --container-architecture linux/amd64 --job build-release --input fast_mode=true" >&2
            exit 1
          fi

      - name: Cache Conan packages
        if: github.actor != 'nektos/act'
        id: cache_conan
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.conan2/p
            ~/.conan2/r
            ~/.conan2/recipes
            ~/.conan2/metadata
            ~/.conan2/s
          key: conan2-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            conan2-${{ runner.os }}-${{ matrix.suffix }}-
            conan2-${{ runner.os }}-
      - name: Conan cache diagnostics
        if: always()
        shell: bash
        run: |
          echo "Cache hit: ${{ steps.cache_conan.outputs.cache-hit }}"
          for d in p r recipes metadata s; do
            if [ -d "$HOME/.conan2/$d" ]; then
              echo "Directory $d present: $(find $HOME/.conan2/$d -mindepth 1 -maxdepth 1 | wc -l | tr -d ' ')" entries || true
              du -sh $HOME/.conan2/$d 2>/dev/null || true
            else
              echo "Directory $d missing"
            fi
          done
      - name: Cache macOS build directory
        if: runner.os == 'macOS' && github.actor != 'nektos/act'
        uses: actions/cache@v4
        with:
          path: build/release
          key: macos-build-${{ matrix.suffix }}-${{ hashFiles('meson.build', 'meson_options.txt') }}-${{ hashFiles('src/**', 'include/**') }}
          restore-keys: |
            macos-build-${{ matrix.suffix }}-

      - name: Cache ccache
        if: github.actor != 'nektos/act'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/ccache
            ~/.ccache
          key: ccache-${{ runner.os }}-${{ matrix.suffix }}-${{ hashFiles('conanfile.py', 'meson.build', 'meson_options.txt') }}
          restore-keys: |
            ccache-${{ runner.os }}-${{ matrix.suffix }}-
            ccache-${{ runner.os }}-

      - name: Install optional system dependencies (Linux only)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          # Add rpm / fakeroot / dpkg-dev so CPack can emit .deb and .rpm packages
          sudo apt-get install -y --no-install-recommends \
            liburing-dev \
            libarchive-dev \
            libtag1-dev \
            libboost-all-dev \
            pkg-config \
            ccache \
            rpm \
            fakeroot \
            dpkg-dev \
            meson \
            cmake \
            ninja-build \
            clang \
            clang-tools \
            lld
          echo "Installed optional packages: liburing-dev libarchive-dev libtag1-dev libboost-all-dev ccache rpm fakeroot dpkg-dev meson cmake ninja-build clang clang-tools lld"
          # Ensure compilers are preferred
          echo "CC=clang" >> $GITHUB_ENV
          echo "CXX=clang++" >> $GITHUB_ENV

      - name: Sanitize stdlib flags (macOS only)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # Remove any accidentally injected libstdc++ selections and force libc++
          for var in CXXFLAGS CFLAGS LDFLAGS; do
            current="${!var:-}"
            sanitized="$(echo "$current" | sed -E 's/-stdlib=libstdc\+\+//g') -stdlib=libc++"
            # Collapse whitespace
            sanitized="$(echo "$sanitized" | tr -s ' ')"
            echo "$var=$sanitized" >> "$GITHUB_ENV"
            printf '%s\n' "$var=$sanitized"
          done
          echo "Stdlib flags sanitized for macOS (forcing -stdlib=libc++)."

      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"
          SHORT_HASH=$(git rev-parse --short HEAD)

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          elif [ "$EVENT" = "workflow_run" ]; then
            # workflow_run triggers from main branch after Tests complete
            channel="nightly"
          else
            channel="stable"
          fi

          # Derive version and tag
          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
            RELEASE_NAME="YAMS ${VERSION}"
          elif [ "$channel" = "nightly" ]; then
            DATE_ISO=$(date -u +%Y-%m-%d)
            DATE_COMPACT=$(date -u +%Y%m%d)
            VERSION="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            TAG_OUT="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            RELEASE_NAME="YAMS Nightly ${DATE_ISO} (${SHORT_HASH})"
          else # weekly
            YEAR=$(date -u +%G)   # ISO week-numbering year
            WEEK=$(date -u +%V)   # ISO week number 01-53
            VERSION="weekly-${YEAR}w${WEEK}-${SHORT_HASH}"
            TAG_OUT="$VERSION"
            RELEASE_NAME="YAMS Weekly ${YEAR}-w${WEEK} (${SHORT_HASH})"
          fi

          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 --match='v*' 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          echo "release_name=$RELEASE_NAME" >> "$GITHUB_OUTPUT"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT, name=$RELEASE_NAME"

      - name: Download CI benchmark artifacts (-yams, if available)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: benchmark-results-linux-hosted-yams
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI benchmark artifacts (legacy -conan, fallback)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: benchmark-results-linux-hosted-conan
          path: ci-artifacts/benchmarks
          if_no_artifact_found: warn

      - name: Download CI coverage (if available)
        if: github.event_name == 'workflow_run' && matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: dawidd6/action-download-artifact@v6
        continue-on-error: true
        with:
          run_id: ${{ github.event.workflow_run.id }}
          workflow_conclusion: completed
          name: coverage-report
          path: ci-artifacts/coverage
          if_no_artifact_found: warn


      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable' && github.actor != 'nektos/act'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      # Hosted runners: install and configure Conan (self-hosted must already be configured)
      - name: Install Conan (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set -euo pipefail
          if [ "$RUNNER_OS" = "macOS" ]; then
            brew update
            brew install pipx || true
            python3 -m pipx ensurepath || true
          elif [ "$RUNNER_OS" = "Linux" ]; then
            sudo apt-get update
            sudo apt-get install -y --no-install-recommends pipx || true
            python3 -m pipx ensurepath || true
          fi
          PY_USER_BIN="$(python3 -m site --user-base 2>/dev/null)/bin"
          [ -d "$PY_USER_BIN" ] && echo "$PY_USER_BIN" >> "$GITHUB_PATH" || true
          [ -d "$HOME/.local/bin" ] && echo "$HOME/.local/bin" >> "$GITHUB_PATH" || true
          export PATH="$HOME/.local/bin:$PY_USER_BIN:$PATH"
          pipx --version || true
          pipx install --python python3 conan || pipx install conan
          which conan || { echo 'Conan not found on PATH after installation'; ls -al "$HOME/.local/bin" || true; exit 127; }
          conan --version
          mkdir -p ~/.conan2
          # Best-effort: global.conf may not exist in repo for hosted macOS
          cp .conan/global.conf ~/.conan2/global.conf 2>/dev/null || true

      - name: Ensure build tools (meson, ninja) for local runners/act
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set -euo pipefail
          if [ "$RUNNER_OS" = "macOS" ]; then
            brew update || true
            brew install meson ninja ccache || true
          elif [ "$RUNNER_OS" = "Linux" ]; then
            python3 -m pip install --user --upgrade meson 'ninja>=1.10' || python -m pip install --user --upgrade meson 'ninja>=1.10'
            if [ -n "${GITHUB_PATH:-}" ]; then
              echo "$HOME/.local/bin" >> "$GITHUB_PATH"
            else
              export PATH="$HOME/.local/bin:$PATH"
            fi
          fi
          echo "meson version: $(meson --version || true)"
          echo "ninja version: $(ninja --version || true)"

      - name: Ensure meson and ninja (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # If meson or ninja are not on PATH, install via Homebrew for robustness
          NEED_INSTALL=0
          command -v meson >/dev/null 2>&1 || NEED_INSTALL=1
          command -v ninja >/dev/null 2>&1 || NEED_INSTALL=1
          if [ "$NEED_INSTALL" -eq 1 ]; then
            brew update || true
            brew install meson ninja || true
          fi
          echo "meson version (post-check): $(meson --version || echo 'missing')"
          echo "ninja version (post-check): $(ninja --version || echo 'missing')"

      - name: Setup ccache env
        shell: bash
        run: |
          echo "CCACHE_DIR=$HOME/.cache/ccache" >> $GITHUB_ENV
          echo "CCACHE_BASEDIR=$GITHUB_WORKSPACE" >> $GITHUB_ENV
          echo "CCACHE_COMPRESS=1" >> $GITHUB_ENV
          echo "CCACHE_MAXSIZE=700M" >> $GITHUB_ENV
          ccache -z 2>/dev/null || true

      - name: Setup Conan (hosted Linux/macOS)
        if: ${{ matrix.hosted  }}
        shell: bash
        run: |
          set -e
          conan profile detect --force
          echo "Conan detected default profile. A platform-specific profile (host-macos-apple-clang or host-linux-clang) will be applied explicitly later."

      - name: Detect clang version (log only)
        shell: bash
        run: |
          set -euo pipefail
          # Prefer clang++, fallback to clang
          if command -v clang++ >/dev/null 2>&1; then
            RAW_VER=$(clang++ --version | sed -E -n 's/.*version ([0-9]+).*/\1/p' | head -1 || true)
          elif command -v clang >/dev/null 2>&1; then
            RAW_VER=$(clang --version | sed -E -n 's/.*version ([0-9]+).*/\1/p' | head -1 || true)
          else
            RAW_VER=""
          fi
          if [ -z "$RAW_VER" ]; then
            echo "Could not auto-detect clang version; using profile defaults" >&2
          else
            echo "Detected clang major: $RAW_VER"
          fi
      - name: Compare profile vs detected clang (advice)
        shell: bash
        run: |
          set -euo pipefail
          PROFILE_FILE="./conan/profiles/host-linux-clang"
          if [ -f "$PROFILE_FILE" ]; then
            PROFILE_VER=$(grep -E '^compiler.version=' "$PROFILE_FILE" | sed -E 's/.*=//')
          else
            PROFILE_VER="(missing profile)"
          fi
          if command -v clang++ >/dev/null 2>&1; then
            SYS_VER=$(clang++ --version | sed -E -n 's/.*version ([0-9]+).*/\1/p' | head -1 || true)
          elif command -v clang >/dev/null 2>&1; then
            SYS_VER=$(clang --version | sed -E -n 's/.*version ([0-9]+).*/\1/p' | head -1 || true)
          else
            SYS_VER="unknown"
          fi
          echo "Profile declares clang version: $PROFILE_VER"
          echo "System detected clang version: $SYS_VER"
          if [ -n "$SYS_VER" ] && [ "$SYS_VER" != "unknown" ] && [ "$PROFILE_VER" != "$SYS_VER" ]; then
            echo "NOTE: Mismatch between profile (clang $PROFILE_VER) and system (clang $SYS_VER)." >&2
            echo "      Consider either installing clang-$PROFILE_VER or adjusting profile to $SYS_VER for local/act runs to avoid subtle ABI or flag differences." >&2
          fi

      - name: Check Conan (self-hosted sanity)
        if: ${{ !matrix.hosted }}
        shell: bash
        run: conan --version || echo "Conan is expected to be pre-installed and configured on self-hosted runners"

      # Hosted runners: clean corrupted cache if needed
      - name: Clean corrupted Conan cache if needed (hosted only)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          if ! conan list "*" 2>/dev/null;
          then
            echo "Conan cache appears corrupted, cleaning locks and temp files..."
            conan cache clean --locks --temp 2>/dev/null || true
            echo "Conan cache locks/temp cleaned"
          fi

      - name: Install system dependencies (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          brew update
          brew install pkg-config cmake ninja meson ccache boost || true
          # Ensure Meson/Ninja are present even if Homebrew failed to link binaries.
          command -v meson >/dev/null 2>&1 || python3 -m pip install --user --upgrade meson
          command -v ninja >/dev/null 2>&1 || python3 -m pip install --user --upgrade 'ninja>=1.10'
          echo "meson version: $(meson --version || echo 'missing')"
          echo "ninja version: $(ninja --version || echo 'missing')"

      - name: Tune Conan client (parallel downloads)
        shell: bash
        run: |
          set -euo pipefail
          CONF_FILE="$HOME/.conan2/global.conf"
          LINE="core.download:parallel=8"
          mkdir -p "$(dirname "$CONF_FILE")"
          if [ -f "$CONF_FILE" ]; then
            TMP_FILE="$(mktemp)"
            awk -v line="$LINE" '
              BEGIN { replaced = 0 }
              /^core.download:parallel=/ { if (!replaced) { print line; replaced = 1 } ; next }
              { print }
              END { if (!replaced) print line }
            ' "$CONF_FILE" > "$TMP_FILE"
            mv "$TMP_FILE" "$CONF_FILE"
          else
            printf '%s\n' "$LINE" > "$CONF_FILE"
          fi
          echo "Configured $LINE in $CONF_FILE"
          grep -n '^core.download:parallel=' "$CONF_FILE" || true
          conan config show core.download:parallel 2>/dev/null || true
          conan --version

      - name: Warm key Conan packages (best-effort)
        if: ${{ matrix.hosted }}
        shell: bash
        run: |
          set +e
          # Try to prefetch heavy packages to minimize build-time compiles
          for ref in \
            openjpeg/2.5.3 \
            pdfium/95.0.4629 \
            onnxruntime/1.18.1 \
            icu/74.1 \
            libarchive/3.7.6; do
            echo "Prefetching $ref ..." || true
            conan download "$ref" -r=conancenter || true
          done
          set -e

      # Windows: Install MSVC and build tools
      - name: Setup MSVC (Windows only)
        if: runner.os == 'Windows'
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: x64

      - name: Install build tools (Windows only)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          # Install Python dependencies
          python -m pip install --upgrade pip
          python -m pip install conan meson ninja

          # Install WiX for MSI packaging
          dotnet tool install --global wix
          wix extension add -g WixToolset.UI.wixext

          # Verify tools
          conan --version
          meson --version
          ninja --version
          wix --version

      - name: Configure and Build Release (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          Write-Host "Building release for Windows x86_64"

          # Set version
          $env:YAMS_EXTRA_MESON_FLAGS = "-Dyams-version=${{ steps.meta.outputs.version }}"

          # Run the build via setup.ps1
          .\setup.ps1 -BuildType Release

          # Set BUILD_DIR for subsequent steps
          "BUILD_DIR=build/release" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append

      # Release build for Linux/macOS targets
      - name: Configure and Build Release (Optimized)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          echo "Optimized release build for ${{ matrix.suffix }}"
          # Align build directory with README (build/release)
          rm -rf build/release
          
          # Determine host profile and architecture based on platform
          if [ "$RUNNER_OS" = "macOS" ]; then
            case "${{ matrix.suffix }}" in
              macos-arm64) 
                HOST_PROFILE="./conan/profiles/host-macos-apple-clang"
                ARCH="armv8" 
                ;;
              macos-x86_64) 
                HOST_PROFILE="./conan/profiles/host-macos-apple-clang-x86"
                ARCH="x86_64" 
                ;;
            esac
          elif [ "$RUNNER_OS" = "Linux" ]; then
            HOST_PROFILE="./conan/profiles/host-linux-clang"
            case "${{ matrix.suffix }}" in
              linux-arm64) ARCH="armv8" ;;
              linux-x86_64) ARCH="x86_64" ;;
            esac
          fi
          
          # Use setup.sh with CI environment variables for consistent configuration
          export YAMS_CONAN_HOST_PROFILE="$HOST_PROFILE"
          export YAMS_CONAN_ARCH="$ARCH"
          export YAMS_EXTRA_MESON_FLAGS="-Dyams-version=${{ steps.meta.outputs.version }} -Dwerror=false -Dwarning_level=2 -Denable-lzma=auto ${{ matrix.meson_args }}"
          
          # Set install prefix: /usr for Linux packages, /usr/local for macOS
          if [ "$RUNNER_OS" = "Linux" ]; then
            export YAMS_INSTALL_PREFIX="/usr"
          else
            export YAMS_INSTALL_PREFIX="/usr/local"
          fi
          
          # For cross-compilation, ensure pkg-config is available
          export PKG_CONFIG="$(command -v pkg-config)"
          echo "Using pkg-config: $PKG_CONFIG"
          
          # Pass version to Meson via extra flags
          VERSION="${{ steps.meta.outputs.version }}"
          export YAMS_EXTRA_MESON_FLAGS="-Dyams-version=${VERSION}"
          echo "Setting version: ${VERSION}"
          
          ./setup.sh Release
          meson compile -C build/release
          echo "BUILD_DIR=build/release" >> $GITHUB_ENV

      - name: Upload build logs (artifacts)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ matrix.suffix }}-${{ github.run_number }}
          path: |
            build/release/meson-logs/
            build/release/meson-info/
            build/release/meson-logs/meson-log.txt
            build/release/build-release/conan/**/*.log
          if-no-files-found: ignore
          retention-days: 14

      - name: ccache stats (post-build)
        shell: bash
        run: |
          ccache -s || echo "ccache stats unavailable"

      - name: Collect benchmark results
        shell: bash
        run: |
          mkdir -p "$BUILD_DIR/bench_results"
          # Collect from validation build (if Linux hosted ran validation)
          if [ -f "build/release/bench_results.json" ]; then
            cp build/release/bench_results.json "$BUILD_DIR/bench_results/"
            echo "Collected benchmark results from validation build"
          fi
          # Also check CI artifacts if available
          if [ -d "ci-artifacts/benchmarks" ] && [ "$(ls -A ci-artifacts/benchmarks/*.json 2>/dev/null)" ]; then
            cp ci-artifacts/benchmarks/*.json "$BUILD_DIR/bench_results/" || true
          fi

      - name: Install (Linux/macOS)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          # Ensure BUILD_DIR is properly set
          if [ ! -d "$BUILD_DIR" ]; then
            echo "BUILD_DIR not found at $BUILD_DIR, attempting fallback to build/release (legacy path build/yams-release no longer used)." >&2
            exit 1
          fi
          # Install to an absolute stage path under the build dir to avoid path duplication
          BD="$(cd "$BUILD_DIR" && pwd)"
          meson install -C "$BD" --destdir "$BD/stage"
          if [ ! -d "$BD/stage" ]; then
            echo "Stage directory missing after meson install" >&2
            ls -al "$BD" >&2 || true
            exit 1
          fi
          echo "STAGE_DIR=$BD/stage" >> "$GITHUB_ENV"

      - name: Install and Package MSI (Windows)
        if: runner.os == 'Windows' && inputs.fast_mode != 'true'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $buildDir = "build\release"
          $stageDir = Join-Path (Resolve-Path $buildDir).Path "stage"
          $version = "${{ steps.meta.outputs.version }}"

          Write-Host "Staging install to: $stageDir"

          # Remove old stage if exists
          if (Test-Path $stageDir) {
              Remove-Item -Recurse -Force $stageDir
          }
          New-Item -ItemType Directory -Path $stageDir -Force | Out-Null

          # Install to stage directory
          meson install -C $buildDir --destdir $stageDir
          if ($LASTEXITCODE -ne 0) {
              Write-Error "Meson install failed"
              exit 1
          }

          # Build MSI using the packaging script
          $msiScript = "packaging\windows\build-msi.ps1"
          & $msiScript -StageDir $stageDir -Version $version -OutputDir $buildDir
          if ($LASTEXITCODE -ne 0) {
              Write-Error "MSI build failed"
              exit 1
          }

          # Move MSI to workspace root for artifact upload
          Get-ChildItem $buildDir -Filter "*.msi" | ForEach-Object {
              Copy-Item $_.FullName -Destination $env:GITHUB_WORKSPACE
              Write-Host "Created MSI: $($_.Name)"
          }

          # Set environment variables for subsequent steps
          "STAGE_DIR=$stageDir" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "BUILD_DIR=$buildDir" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append

      - name: Generate release summary
        shell: bash
        run: |
          echo "### Artifacts" >> "$GITHUB_STEP_SUMMARY"
          echo "[View artifacts for this run]($GITHUB_SERVER_URL/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID)" >> "$GITHUB_STEP_SUMMARY"
          SUMMARY_FILE="$BUILD_DIR/release_summary.md"
          echo "## Release Build Information (${{ steps.meta.outputs.version }})" > "$SUMMARY_FILE"
          echo "" >> "$SUMMARY_FILE"
          echo "**Platform:** ${{ matrix.suffix }}" >> "$SUMMARY_FILE"
          echo "**Build Type:** Release" >> "$SUMMARY_FILE"
          echo "**Channel:** ${{ steps.meta.outputs.channel }}" >> "$SUMMARY_FILE"

          # Only mention CI validation if we actually have CI artifacts
          if [ -d "ci-artifacts" ] && [ "$(ls -A ci-artifacts/ 2>/dev/null)" ]; then
            echo "**CI Status:** Tests and benchmarks from CI workflow" >> "$SUMMARY_FILE"
          fi
          echo "" >> "$SUMMARY_FILE"

          # Add coverage information if available (no python dependency)
          if [ -f "ci-artifacts/coverage/coverage.xml" ]; then
            echo "### Test Coverage" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            # Extract line-rate="0.8234" attribute and convert to percent with one decimal
            raw_rate=$(grep -Eo 'line-rate="[0-9.]+"' ci-artifacts/coverage/coverage.xml | head -1 | sed -E 's/.*="([0-9.]+)"/\1/') || raw_rate=""
            if [ -n "$raw_rate" ]; then
              # Use awk for safe float multiplication & formatting
              coverage_pct=$(awk -v r="$raw_rate" 'BEGIN{ printf("%.1f%%", r*100) }')
            else
              coverage_pct="N/A"
            fi
            echo "**Line Coverage:** $coverage_pct" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
          fi

          # Add benchmark results if available from CI or validation (jq preferred, fallback to grep)
          if [ -d "$BUILD_DIR/bench_results" ] && ls "$BUILD_DIR/bench_results"/*.json >/dev/null 2>&1; then
            echo "### Performance Metrics" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            echo "| Benchmark | Time (ns/op) | CPU (ns/op) | Memory |" >> "$SUMMARY_FILE"
            echo "|-----------|--------------|-------------|--------|" >> "$SUMMARY_FILE"
            if command -v jq >/dev/null 2>&1; then
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                jq -r '.benchmarks[]? | "| ".name // "Unknown" | ".real_time // 0 | floor) | ".cpu_time // 0 | floor) | "' "$json_file" 2>/dev/null | while IFS= read -r line; do
                  name=$(echo "$line" | cut -d'|' -f2 | sed 's/^ *//;s/ *$//')
                  rtime=$(echo "$line" | cut -d'|' -f3 | tr -d ' ')
                  ctime=$(echo "$line" | cut -d'|' -f4 | tr -d ' ')
                  # Derive memory throughput if bytes_per_second present
                  mem=$(jq -r --arg n "$name" '.benchmarks[]? | select(.name==$n) | if (.bytes_per_second // 0) > 0 then ((.bytes_per_second/1024/1024)|tostring)+" MB/s" else (if (.items_per_second // 0) > 0 then ((.items_per_second)|tostring)+" ops/s" else "N/A" end) end' "$json_file" 2>/dev/null)
                  [ -z "$mem" ] && mem="N/A"
                  echo "| $name | $rtime | $ctime | $mem |" >> "$SUMMARY_FILE"
                done
              done
            else
              # Minimal fallback: grep fields (less robust)
              for json_file in "$BUILD_DIR/bench_results"/*.json; do
                grep '"name"' "$json_file" | sed -E 's/.*"name": *"([^"]+)".*/| \1 | ? | ? | N/A |/' >> "$SUMMARY_FILE" || true
              done
            fi
            echo "" >> "$SUMMARY_FILE"
          fi

          echo "Generated release summary at: $SUMMARY_FILE"
          cat "$SUMMARY_FILE"

      - name: Package
        if: ${{ inputs.fast_mode != 'true' && github.actor != 'nektos/act' }}
        shell: bash
        run: |
          STAGE_PATH="${{ env.STAGE_DIR }}"
          if [ ! -d "$STAGE_PATH" ]; then
            echo "Stage directory not found at $STAGE_PATH" >&2
            ls -al "$BUILD_DIR" >&2 || true
            exit 1
          fi
          cd "$STAGE_PATH"
          VERSION="${{ steps.meta.outputs.version }}"
          SUFFIX="${{ matrix.suffix }}"
          OUTDIR="$GITHUB_WORKSPACE"
          if [ "${{ matrix.packaging }}" = "zip" ]; then
            ASSET="yams-${VERSION}-${SUFFIX}.zip"
            zip -r "$OUTDIR/$ASSET" .
          else
            ASSET="yams-${VERSION}-${SUFFIX}.tar.gz"
            tar czf "$OUTDIR/$ASSET" .
          fi
          echo "ASSET_PATH=$OUTDIR/$ASSET" >> "$GITHUB_ENV"
          echo "Created asset: $OUTDIR/$ASSET"

      - name: Build Linux packages (DEB/RPM)
        if: ${{ matrix.build_packages == true && matrix.os == 'linux-hosted' && inputs.fast_mode != 'true' && github.actor != 'nektos/act' }}
        env:
          BASE_VERSION: ${{ steps.meta.outputs.base_version }}
        shell: bash
        run: |
          # Package-only: reuse staged install without triggering a rebuild
          # Use BASE_VERSION to generate Debian/RPM policy-compliant versions for nightly/weekly
          chmod +x scripts/build-deb.sh
          scripts/build-deb.sh package_only "${{ steps.meta.outputs.version }}" "${{ env.BUILD_DIR }}" "stage"
          
          # Move packages to root directory for artifact upload
          if ls "${{ env.BUILD_DIR }}"/yams-*.deb 1> /dev/null 2>&1; then
            mv "${{ env.BUILD_DIR }}"/yams-*.deb ./ || true
          fi
          if ls "${{ env.BUILD_DIR }}"/yams-*.rpm 1> /dev/null 2>&1; then
            mv "${{ env.BUILD_DIR }}"/yams-*.rpm ./ || true
          fi

      # Release notes are sourced directly from CHANGELOG.md during release creation

      - name: Publish matrix.json (expected platform count)
        if: matrix.os == 'linux-hosted'
        shell: bash
        run: |
          # Only generate once (linux-hosted) to avoid artifact name collision across matrix entries.
          # Update to reflect current matrix total (5 platforms: linux-x86_64, linux-arm64, macos-arm64, macos-x86_64, windows-x86_64)
          echo '{"total": 5}' > matrix.json

      - name: Upload matrix metadata
        if: matrix.os == 'linux-hosted' && github.actor != 'nektos/act'
        uses: actions/upload-artifact@v4
        with:
          name: matrix-meta
          path: matrix.json
          retention-days: 1

      - name: Upload Release Artifacts
        if: github.actor != 'nektos/act'
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ matrix.suffix }}-files${{ github.run_attempt > 1 && format('-a{0}', github.run_attempt) || '' }}
          path: |
            yams-*.tar.gz
            yams-*.zip
            yams-*.msi
            yams-*.msi.sha256
            ${{ env.BUILD_DIR }}/release_summary.md
            ${{ env.BUILD_DIR }}/bench_results/*.json
            yams-*.deb
            yams-*.rpm
            yams-*.AppImage
            yams-*.pkg
          retention-days: 1

      - name: Verify Linux package artifacts
        if: ${{ matrix.os == 'linux-hosted' && github.actor != 'nektos/act' && inputs.fast_mode != 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          echo "Verifying expected Linux package artifacts (DEB/RPM)"
          ls -1 yams-*linux-x86_64.deb 2>/dev/null || { echo "ERROR: Missing .deb package" >&2; exit 1; }
          if command -v rpmbuild >/dev/null 2>&1; then
            ls -1 yams-*linux-x86_64.rpm 2>/dev/null || { echo "ERROR: Missing .rpm package" >&2; exit 1; }
          else
            echo "rpmbuild unavailable; RPM check skipped" >&2
          fi
          echo "Linux package verification complete"

  create-release:
    name: Create GitHub Release
    needs: [check-commits, build-release]
    runs-on: ubuntu-latest
    # Skip release creation when: running under act, OR check-commits skipped release
    if: |
      always() && !cancelled() && 
      github.actor != 'nektos/act' &&
      (needs.check-commits.result == 'skipped' || needs.check-commits.outputs.has_new_commits == 'true' || github.event_name == 'push' || github.event_name == 'workflow_dispatch') &&
      needs.build-release.result == 'success'
    permissions:
      contents: write
      actions: read
    env:
      CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
      CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      CLOUDFLARE_ENDPOINT: ${{ secrets.CLOUDFLARE_ENDPOINT }}
      R2_PREFIX: ${{ secrets.R2_PREFIX }}
      R2_BUCKET: ${{ secrets.R2_BUCKET }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: false
          repository: ${{ github.event.workflow_run.head_repository.full_name || github.repository }}
          ref: ${{ github.event.workflow_run.head_sha || github.ref }}

      - name: Determine release channel and version/tag
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          EVENT="${{ github.event_name }}"
          SCHEDULE_CRON="${{ github.event.schedule || '' }}"
          INPUT_CHANNEL="${{ inputs.channel || '' }}"
          SHORT_HASH=$(git rev-parse --short HEAD)

          channel=""
          if [ "$EVENT" = "push" ]; then
            channel="stable"
          elif [ "$EVENT" = "workflow_dispatch" ] && [ -n "$INPUT_CHANNEL" ]; then
            case "$INPUT_CHANNEL" in
              stable|weekly|nightly) channel="$INPUT_CHANNEL" ;;
              *) channel="nightly" ;;
            esac
          elif [ "$EVENT" = "schedule" ]; then
            if [ "$SCHEDULE_CRON" = "0 3 * * 1" ]; then
              channel="weekly"
            else
              channel="nightly"
            fi
          elif [ "$EVENT" = "workflow_run" ]; then
            # workflow_run triggers from main branch after Tests complete
            channel="nightly"
          else
            channel="stable"
          fi

          # Derive version and tag
          if [ "$channel" = "stable" ]; then
            TAG="${GITHUB_REF_NAME}"
            VERSION="${TAG#v}"
            TAG_OUT="${GITHUB_REF_NAME}"
            RELEASE_NAME="YAMS ${VERSION}"
          elif [ "$channel" = "nightly" ]; then
            DATE_ISO=$(date -u +%Y-%m-%d)
            DATE_COMPACT=$(date -u +%Y%m%d)
            VERSION="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            TAG_OUT="nightly-${DATE_COMPACT}-${SHORT_HASH}"
            RELEASE_NAME="YAMS Nightly ${DATE_ISO} (${SHORT_HASH})"
          else # weekly
            YEAR=$(date -u +%G)   # ISO week-numbering year
            WEEK=$(date -u +%V)   # ISO week number 01-53
            VERSION="weekly-${YEAR}w${WEEK}-${SHORT_HASH}"
            TAG_OUT="$VERSION"
            RELEASE_NAME="YAMS Weekly ${YEAR}-w${WEEK} (${SHORT_HASH})"
          fi

          BASE_NUMERIC_VERSION="$(git describe --tags --abbrev=0 --match='v*' 2>/dev/null || echo 0.0.0)"
          BASE_NUMERIC_VERSION="${BASE_NUMERIC_VERSION#v}"

          echo "channel=$channel" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=$TAG_OUT" >> "$GITHUB_OUTPUT"
          echo "release_name=$RELEASE_NAME" >> "$GITHUB_OUTPUT"
          echo "base_version=$BASE_NUMERIC_VERSION" >> "$GITHUB_OUTPUT"
          if [ "$channel" = "stable" ]; then
            echo "prerelease=false" >> "$GITHUB_OUTPUT"
          else
            echo "prerelease=true" >> "$GITHUB_OUTPUT"
          fi

          echo "Detected channel=$channel, version=$VERSION, tag=$TAG_OUT, name=$RELEASE_NAME"

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts
          pattern: "*"

      - name: List downloaded artifacts (debug)
        shell: bash
        run: |
          echo "Downloaded artifact directories:" >&2
          find release-artifacts -maxdepth 2 -type f -printf '%P\n' 2>/dev/null || true

      - name: Collect assets into staging directory
        shell: bash
        run: |
          set -euo pipefail
          rm -rf assets || true
          mkdir -p assets
          # Collect all per-platform release artifacts
          for dir in release-artifacts/release-*; do
            [ -d "$dir" ] || continue
            # Archives
            cp -v $dir/*.tar.gz assets/ 2>/dev/null || true
            cp -v $dir/*.zip assets/ 2>/dev/null || true
            # Packages
            cp -v $dir/*.deb assets/ 2>/dev/null || true
            cp -v $dir/*.rpm assets/ 2>/dev/null || true
            cp -v $dir/*.AppImage assets/ 2>/dev/null || true
            # Windows MSI packages
            cp -v $dir/*.msi assets/ 2>/dev/null || true
            # Summaries & bench json
            if [ -d "$dir/bench_results" ]; then
              cp -v $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
            if [ -f "$dir/release_summary.md" ]; then
              cp -v "$dir/release_summary.md" "assets/release_summary-$(basename "$dir").md" 2>/dev/null || true
            fi
          done
          echo "Final assets content:" >&2
          ls -al assets >&2 || true

      - name: Generate checksums
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "Generating SHA256SUMS for release assets" >&2
          # Exclude bench JSON and summaries from checksum manifest (only distributable binaries)
          # Check if any distributable files exist before creating SHA256SUMS
          if ls -1 | grep -qE '\.(tar.gz|zip|deb|rpm|AppImage|pkg|msi)$' 2>/dev/null; then
            ls -1 | grep -E '\.(tar.gz|zip|deb|rpm|AppImage|pkg|msi)$' | while read -r f; do
              sha256sum "$f" >> SHA256SUMS
            done
            sort -o SHA256SUMS SHA256SUMS
            echo "Created checksum manifest:" >&2
            cat SHA256SUMS >&2
          else
            echo "No distributable assets found; creating empty SHA256SUMS" >&2
            touch SHA256SUMS
          fi

      - name: Initialize yams-repo submodule (for R2 bucket config)
        if: (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.upload_r2 == 'true'))
        shell: bash
        run: |
          git submodule update --init external/yams-repo || echo "Failed to initialize yams-repo submodule"

      - name: Install Wrangler CLI
        if: (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.upload_r2 == 'true')) && env.CLOUDFLARE_ACCOUNT_ID != '' && env.CLOUDFLARE_API_TOKEN != ''
        shell: bash
        run: |
          npm i -g wrangler

      - name: Upload assets to Cloudflare R2 (Wrangler)
        if: (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.upload_r2 == 'true')) && env.CLOUDFLARE_ACCOUNT_ID != '' && env.CLOUDFLARE_API_TOKEN != ''
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ENDPOINT: ${{ secrets.CLOUDFLARE_ENDPOINT }}
          R2_PREFIX: ${{ secrets.R2_PREFIX }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          # Resolve bucket name: prefer secret R2_BUCKET, else parse wrangler.toml if present
          BUCKET="${R2_BUCKET:-}"
          if [ -z "$BUCKET" ] && [ -f "$GITHUB_WORKSPACE/external/yams-repo/worker/wrangler.toml" ]; then
            BUCKET=$(sed -E -n 's/^bucket_name\s*=\s*"(.*)"/\1/p' "$GITHUB_WORKSPACE/external/yams-repo/worker/wrangler.toml" | head -1)
          fi
          if [ -z "$BUCKET" ]; then
            echo "Skipping R2 upload: no R2_BUCKET secret and wrangler.toml missing or without bucket_name." >&2
            exit 0
          fi
          echo "Uploading to R2 bucket: $BUCKET (prefix='${R2_PREFIX:-}')"
          
          # Upload latest.json manifest with JSON content-type
          if [ -f latest.json ]; then
            wrangler r2 object put "${BUCKET}/${R2_PREFIX:-}latest.json" --file=latest.json --content-type application/json
          fi
          
          # Upload complete APT repository structure if available
          if [ -d "$GITHUB_WORKSPACE/aptrepo" ]; then
            echo "Uploading APT repository to R2..."
            cd "$GITHUB_WORKSPACE/aptrepo"
            find . -type f | while read -r f; do
              key="${R2_PREFIX:-}aptrepo/${f#./}"
              wrangler r2 object put "${BUCKET}/${key}" --file="$f"
            done
            cd "$GITHUB_WORKSPACE/assets"
          fi
          
          # Upload complete YUM repository structure if available
          if [ -d "$GITHUB_WORKSPACE/yumrepo" ]; then
            echo "Uploading YUM repository to R2..."
            cd "$GITHUB_WORKSPACE/yumrepo"
            find . -type f | while read -r f; do
              key="${R2_PREFIX:-}yumrepo/${f#./}"
              wrangler r2 object put "${BUCKET}/${key}" --file="$f"
            done
            cd "$GITHUB_WORKSPACE/assets"
          fi
          
          # Upload distributable assets (archives for direct download)
          shopt -s nullglob
          for f in *.tar.gz *.zip *.AppImage; do
            [ -f "$f" ] || continue
            DEST="${BUCKET}/${R2_PREFIX:-}${f}"
            wrangler r2 object put "$DEST" --file="$f"
          done

      - name: (Optional) Import GPG key and sign checksums
        if: env.GPG_PRIVATE_KEY && env.GPG_PRIVATE_KEY != ''
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY || '' }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE || '' }}
        shell: bash
        run: |
          set -euo pipefail
          cd assets
          echo "GPG key present: generating detached signature for SHA256SUMS" >&2
          echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --import
          gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" --detach-sign --armor -o SHA256SUMS.asc SHA256SUMS
          echo "Signature generated (SHA256SUMS.asc)" >&2

      - name: Verify asset set
        id: asset_check
        shell: bash
        run: |
          COUNT=$(find assets -type f | wc -l | tr -d ' ')
          echo "Discovered $COUNT asset files" >&2
          echo "file_count=$COUNT" >> $GITHUB_OUTPUT
          if [ "$COUNT" -eq 0 ]; then
            echo "ERROR: No asset files assembled for release." >&2
            exit 1
          fi

      - name: Generate Homebrew formula (stable only)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          TAG="${{ steps.meta.outputs.tag }}"
          VERSION="${{ steps.meta.outputs.version }}"
          FORMULA_DIR="homebrew"
          mkdir -p "$FORMULA_DIR"
          
          # Download macOS binaries and compute SHA256s
          ARM64_URL="https://github.com/${{ github.repository }}/releases/download/${TAG}/yams-${VERSION}-macos-arm64.zip"
          X86_64_URL="https://github.com/${{ github.repository }}/releases/download/${TAG}/yams-${VERSION}-macos-x86_64.zip"
          
          echo "Downloading macOS ARM64 binary: $ARM64_URL" >&2
          curl -Ls -o "yams-macos-arm64.zip" "$ARM64_URL"
          SHA256_ARM64=$(shasum -a 256 "yams-macos-arm64.zip" | awk '{print $1}')
          echo "Computed ARM64 sha256: $SHA256_ARM64" >&2
          
          echo "Downloading macOS x86_64 binary: $X86_64_URL" >&2
          curl -Ls -o "yams-macos-x86_64.zip" "$X86_64_URL"
          SHA256_X86_64=$(shasum -a 256 "yams-macos-x86_64.zip" | awk '{print $1}')
          echo "Computed x86_64 sha256: $SHA256_X86_64" >&2
          
          TEMPLATE_PATH="packaging/homebrew/yams.rb.template"
          if [ ! -f "$TEMPLATE_PATH" ]; then
            echo "ERROR: Homebrew template not found at $TEMPLATE_PATH" >&2
            exit 1
          fi
          OUT_FORMULA="$FORMULA_DIR/yams.rb"
          # Replace template placeholders with release metadata
          sed \
            -e "s|__VERSION__|$VERSION|g" \
            -e "s|__SHA256_ARM64__|$SHA256_ARM64|g" \
            -e "s|__SHA256_X86_64__|$SHA256_X86_64|g" \
            "$TEMPLATE_PATH" > "$OUT_FORMULA"
          echo "Updated formula at $OUT_FORMULA:" >&2
          grep -E 'version\s+"|sha256 "' "$OUT_FORMULA" >&2 || true
          # Create quick install instructions file
          cat > "$FORMULA_DIR/README.txt" <<EOF
          Homebrew formula generated for YAMS $VERSION
          To use without a tap:
            brew install --build-from-source $OUT_FORMULA

          Recommended (create a tap repository and place yams.rb there), e.g.:
            1. Create repo: github.com/<you>/homebrew-yams
            2. Add this formula as Formula/yams.rb
            3. Users run: brew install <you>/yams/yams
          EOF

      - name: Update Homebrew tap submodule (stable only)
        if: steps.meta.outputs.channel == 'stable'
        env:
          HOMEBREW_TAP_TOKEN: ${{ secrets.HOMEBREW_TAP_TOKEN || '' }}
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAP_PATH="homebrew-yams"
          if [ ! -d "$TAP_PATH" ]; then
            echo "Tap submodule not found at $TAP_PATH; skipping tap update" >&2
            exit 0
          fi
          if [ ! -f "homebrew/yams.rb" ]; then
            echo "homebrew/yams.rb not found; skipping tap update" >&2
            exit 0
          fi
          # Only initialize the homebrew-yams submodule, not the Ghidra plugin which needs SSH
          git submodule update --init homebrew-yams
          mkdir -p "$TAP_PATH/Formula"
          cp homebrew/yams.rb "$TAP_PATH/Formula/yams.rb"
          pushd "$TAP_PATH" >/dev/null
          
          # Fetch latest to ensure we have up-to-date main
          if [ -n "${HOMEBREW_TAP_TOKEN:-}" ]; then
            REMOTE="https://x-access-token:${HOMEBREW_TAP_TOKEN}@github.com/${{ github.repository_owner }}/homebrew-yams.git"
            git remote add tap-origin "$REMOTE" 2>/dev/null || git remote set-url tap-origin "$REMOTE"
            git fetch tap-origin main
            git checkout main
            git reset --hard tap-origin/main
          else
            git checkout main
            git pull --ff-only 2>/dev/null || true
          fi
          
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add Formula/yams.rb || true
          if git diff --cached --quiet; then
            echo "Tap formula unchanged; skipping push" >&2
            popd >/dev/null
            exit 0
          fi
          git commit -m "chore(homebrew): update formula to v${VERSION}"
          if [ -n "${HOMEBREW_TAP_TOKEN:-}" ]; then
            git push tap-origin main || echo "Push failed; ensure HOMEBREW_TAP_TOKEN has repo permissions"
          else
            echo "HOMEBREW_TAP_TOKEN not set; manual push required" >&2
          fi
          popd >/dev/null

      - name: Update Homebrew nightly formula (nightly/weekly only)
        if: steps.meta.outputs.channel != 'stable'
        env:
          HOMEBREW_TAP_TOKEN: ${{ secrets.HOMEBREW_TAP_TOKEN || '' }}
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAG="${{ steps.meta.outputs.tag }}"
          TAP_PATH="homebrew-yams"
          
          # Extract date and hash from version (e.g., nightly-20251109-ebd0701)
          DATE=$(echo "$VERSION" | sed -E 's/.*-([0-9]{8})-.*/\1/')
          HASH=$(echo "$VERSION" | sed -E 's/.*-([a-f0-9]{7})$/\1/')
          
          if [ ! -d "$TAP_PATH" ]; then
            echo "Tap submodule not found at $TAP_PATH; skipping nightly formula update" >&2
            exit 0
          fi
          
          # Initialize submodule
          git submodule update --init homebrew-yams
          
          # Download macOS binaries and compute SHA256s
          ARM64_URL="https://github.com/${{ github.repository }}/releases/download/${TAG}/yams-${VERSION}-macos-arm64.zip"
          X86_64_URL="https://github.com/${{ github.repository }}/releases/download/${TAG}/yams-${VERSION}-macos-x86_64.zip"
          
          echo "Downloading macOS ARM64 binary: $ARM64_URL" >&2
          curl -Ls -o "yams-nightly-arm64.zip" "$ARM64_URL"
          SHA256_ARM64=$(shasum -a 256 "yams-nightly-arm64.zip" | awk '{print $1}')
          echo "Computed ARM64 sha256: $SHA256_ARM64" >&2
          
          echo "Downloading macOS x86_64 binary: $X86_64_URL" >&2
          curl -Ls -o "yams-nightly-x86_64.zip" "$X86_64_URL"
          SHA256_X86_64=$(shasum -a 256 "yams-nightly-x86_64.zip" | awk '{print $1}')
          echo "Computed x86_64 sha256: $SHA256_X86_64" >&2
          
          # Update nightly formula
          NIGHTLY_FORMULA="$TAP_PATH/Formula/yams@nightly.rb"
          if [ ! -f "$NIGHTLY_FORMULA" ]; then
            echo "Nightly formula not found at $NIGHTLY_FORMULA; skipping" >&2
            exit 0
          fi
          
          # Replace placeholders
          sed -i.bak \
            -e "s/__VERSION__/${VERSION}/g" \
            -e "s/__TAG__/${TAG}/g" \
            -e "s/__DATE__/${DATE}/g" \
            -e "s/__HASH__/${HASH}/g" \
            -e "s/__SHA256_ARM64__/${SHA256_ARM64}/g" \
            -e "s/__SHA256_X86_64__/${SHA256_X86_64}/g" \
            "$NIGHTLY_FORMULA"
          rm -f "${NIGHTLY_FORMULA}.bak"
          
          pushd "$TAP_PATH" >/dev/null
          git checkout main || git checkout -b main
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add Formula/yams@nightly.rb || true
          if git diff --cached --quiet; then
            echo "Nightly formula unchanged; skipping push" >&2
            popd >/dev/null
            exit 0
          fi
          git commit -m "chore(homebrew): update nightly formula to ${VERSION}"
          if [ -n "${HOMEBREW_TAP_TOKEN:-}" ]; then
            REMOTE="https://x-access-token:${HOMEBREW_TAP_TOKEN}@github.com/${{ github.repository_owner }}/homebrew-yams.git"
            git push "$REMOTE" main || echo "Push failed; ensure HOMEBREW_TAP_TOKEN has repo permissions"
          else
            echo "HOMEBREW_TAP_TOKEN not set; manual push required" >&2
          fi
          popd >/dev/null

      - name: Generate winget manifest (stable only)
        if: steps.meta.outputs.channel == 'stable'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $version = "${{ steps.meta.outputs.version }}"
          $tag = "${{ steps.meta.outputs.tag }}"

          # Find the Windows MSI in assets
          $msiFile = Get-ChildItem -Path "assets" -Filter "*.msi" | Select-Object -First 1
          if (-not $msiFile) {
              Write-Warning "No MSI file found in assets; skipping winget manifest generation"
              exit 0
          }

          Write-Host "Generating winget manifest for version $version"
          Write-Host "MSI file: $($msiFile.FullName)"

          # Run the winget manifest generator
          & ./packaging/windows/generate-winget-manifest.ps1 `
              -Version $version `
              -Tag $tag `
              -MsiPath $msiFile.FullName `
              -GitHubRepo "${{ github.repository }}" `
              -OutputDir "winget-manifests"

          if ($LASTEXITCODE -ne 0) {
              Write-Error "Winget manifest generation failed"
              exit 1
          }

      - name: Upload winget manifest artifact
        if: steps.meta.outputs.channel == 'stable'
        uses: actions/upload-artifact@v4
        with:
          name: winget-manifest
          path: winget-manifests/
          retention-days: 30

      - name: Build APT repository metadata (stable only, linux .deb present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          # Require at least one .deb in assets
          if ! ls assets/*.deb >/dev/null 2>&1; then
            echo "No .deb found; skipping APT repo generation" >&2
            exit 0
          fi
          BASE_VERSION="${{ steps.meta.outputs.base_version }}"
          REPO_ROOT="aptrepo"
          POOL_DIR="$REPO_ROOT/pool/main/y/yams"
          DIST=stable
          COMPONENT=main
          ARCH=amd64
          mkdir -p "$POOL_DIR" "$REPO_ROOT/dists/$DIST/$COMPONENT/binary-$ARCH"
          # Copy & normalize deb naming (yams_<version>_amd64.deb)
          for deb in assets/*.deb; do
            cp "$deb" "$POOL_DIR/$(echo "$deb" | sed -E "s|.*yams-([^-]+)-linux-x86_64\.deb|yams_${BASE_VERSION}_amd64.deb|")" || true
          done
          # Install dpkg-dev if missing (for dpkg-scanpackages)
          if ! command -v dpkg-scanpackages >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y dpkg-dev
          fi
          pushd "$REPO_ROOT" >/dev/null
          dpkg-scanpackages --multiversion pool > dists/$DIST/$COMPONENT/binary-$ARCH/Packages
          gzip -c dists/$DIST/$COMPONENT/binary-$ARCH/Packages > dists/$DIST/$COMPONENT/binary-$ARCH/Packages.gz
          cat > dists/$DIST/Release <<REL
          Origin: YAMS
          Label: YAMS
          Suite: $DIST
          Codename: $DIST
          Architectures: $ARCH
          Components: $COMPONENT
          Description: YAMS APT repository
          REL
          # Optional GPG signing if secret present
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes -abs -o dists/$DIST/Release.gpg dists/$DIST/Release
            gpg --batch --yes --clearsign -o dists/$DIST/InRelease dists/$DIST/Release
          fi
          popd >/dev/null
          tree "$REPO_ROOT" || find "$REPO_ROOT" -maxdepth 4 -type f -print
          cat > "$REPO_ROOT/USAGE.txt" <<EOF
          Add this APT repo (unsigned example):
            curl -fsSL https://${{ github.repository_owner }}.pages.dev/aptrepo/gpg.key -o /usr/share/keyrings/yams.gpg   # (If you later publish a key)
            echo "deb [signed-by=/usr/share/keyrings/yams.gpg] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams

          If unsigned (temporary/testing):
            echo "deb [trusted=yes] https://${{ github.repository_owner }}.pages.dev/aptrepo stable main" | sudo tee /etc/apt/sources.list.d/yams.list
            sudo apt-get update && sudo apt-get install yams
          EOF

      - name: Upload APT repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: apt-repo
          path: aptrepo/
          retention-days: 7

      - name: Build YUM repository metadata (stable only, rpm present)
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          set -euo pipefail
          if ! ls assets/*.rpm >/dev/null 2>&1; then
            echo "No .rpm found; skipping YUM repo generation" >&2
            exit 0
          fi
          YUM_ROOT="yumrepo"
          mkdir -p "$YUM_ROOT"
          cp assets/*.rpm "$YUM_ROOT/" 2>/dev/null || true
          # Install createrepo_c if needed
          if ! command -v createrepo_c >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y createrepo-c
          fi

          createrepo_c "$YUM_ROOT"
          if [ -n "${GPG_PRIVATE_KEY:-}" ]; then
            echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --yes --import
            gpg --batch --yes --detach-sign --armor -o "$YUM_ROOT/repodata/repomd.xml.asc" "$YUM_ROOT/repodata/repomd.xml"
          fi
          cat > "$YUM_ROOT/USAGE.txt" <<EOF
          Add YUM/DNF repo (unsigned example):
            sudo tee /etc/yum.repos.d/yams.repo <<'REPO'
            [yams]
            name=YAMS Repository
            baseurl=https://${{ github.repository_owner }}.pages.dev/yumrepo/
            enabled=1
            gpgcheck=0
            repo_gpgcheck=0
            REPO

          Then install:
            sudo dnf makecache || sudo yum makecache
            sudo dnf install yams || sudo yum install yams

          (Enable gpgcheck once you publish a key and sign RPMs/repodata.)
          EOF

      - name: Upload YUM repo artifact
        if: steps.meta.outputs.channel == 'stable' && always()
        uses: actions/upload-artifact@v4
        with:
          name: yum-repo
          path: yumrepo/
          retention-days: 7

      - name: Generate latest manifest (latest.json)
        shell: bash
        run: |
          set -euo pipefail
          VERSION="${{ steps.meta.outputs.version }}"
          TAG="${{ steps.meta.outputs.tag }}"
            CHANNEL="${{ steps.meta.outputs.channel }}"
          DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          mkdir -p assets
          cd assets
          if [ ! -f SHA256SUMS ]; then
            echo "Missing SHA256SUMS file in assets/; cannot build manifest" >&2
            ls -al >&2 || true
            exit 1
          fi
          # Build assets array JSON using awk (avoid jq dependency); trim trailing comma
          ASSETS_JSON=$(awk '{printf "{\"name\":\"%s\",\"sha256\":\"%s\"},", $2, $1}' SHA256SUMS | sed 's/,$//')
          cat > latest.json <<LJSON
          {
            "version": "${VERSION}",
            "tag": "${TAG}",
            "channel": "${CHANNEL}",
            "published_at": "${DATE}",
            "assets": [${ASSETS_JSON}]
          }
          LJSON
          echo "latest.json manifest (assets/latest.json):" >&2
          sed 's/^/  /' latest.json >&2

      - name: Check existing release (stable only)
        id: existing_release
        shell: bash
        run: |
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Checking if release $TAG already exists" >&2
          if command -v gh >/dev/null 2>&1; then
            if gh release view "$TAG" >/dev/null 2>&1; then
              echo "exists=true" >> $GITHUB_OUTPUT
            else
              echo "exists=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "gh CLI not installed; skipping existence check" >&2
            echo "exists=unknown" >> $GITHUB_OUTPUT
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Check job completion status
        id: check-status
        shell: bash
        run: |
          # Discover expected platforms from matrix job names in this run
          JOBS_JSON=$(curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                           -H "Accept: application/vnd.github.v3+json" \
                           -s "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100")
          # Extract unique platform identifiers from "Build and Release (<platform>)" job names
          EXPECTED_PLATFORMS=$(echo "$JOBS_JSON" | sed -n 's/.*"name"[[:space:]]*:[[:space:]]*"\(Build and Release ([^\"]*)\)".*/\1/p' | sed -n 's/Build and Release (\(.*\))/\1/p' | sort -u)
          TOTAL_EXPECTED=$(echo "$EXPECTED_PLATFORMS" | grep -c . || true)

          # Count successful artifacts from downloaded files (release-*)
          if [ -d "release-artifacts" ]; then
            # Count per-platform artifact directories (robust against file/dir listing quirks)
            SUCCESS_COUNT=$(find "release-artifacts" -mindepth 1 -maxdepth 1 -type d -name 'release-*' 2>/dev/null | grep -c . || true)
          else
            SUCCESS_COUNT=0
          fi

          # Determine expected builds:
          # 1) Prefer matrix.json (if provided)
          # 2) Otherwise, fall back to number of artifact groups downloaded
          if [ -f "release-artifacts/matrix.json" ]; then
            TOTAL_EXPECTED=$(cat "release-artifacts/matrix.json" | tr -d '\r' | grep -Eo '"total"[[:space:]]*:[[:space:]]*[0-9]+' | grep -Eo '[0-9]+' | head -1)
          fi
          if [ -z "$TOTAL_EXPECTED" ] || [ "$TOTAL_EXPECTED" -eq 0 ]; then
            TOTAL_EXPECTED="$SUCCESS_COUNT"
          fi

          # Compute dynamic threshold = ceil(TOTAL_EXPECTED / 2)
          THRESHOLD=$(( (TOTAL_EXPECTED + 1) / 2 ))

          echo "Successful builds: $SUCCESS_COUNT out of $TOTAL_EXPECTED (threshold: $THRESHOLD)"

          if [ "$SUCCESS_COUNT" -lt "$THRESHOLD" ]; then
            echo "ERROR: Need at least $THRESHOLD successful builds to create release (out of $TOTAL_EXPECTED expected)"
            exit 1
          fi

          echo "success_count=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "total_expected=$TOTAL_EXPECTED" >> $GITHUB_OUTPUT
          echo "threshold=$THRESHOLD" >> $GITHUB_OUTPUT

      - name: Extract release notes from CHANGELOG.md (stable only)
        id: changelog
        if: steps.meta.outputs.channel == 'stable'
        uses: ffurrer2/extract-release-notes@v2
        with:
          changelog_file: CHANGELOG.md

      - name: Extract grouped changelogs for minor version (stable only)
        id: grouped-changelog
        if: steps.meta.outputs.channel == 'stable'
        shell: bash
        run: |
          # Extract minor version from current tag
          CURRENT_VERSION="${{ steps.meta.outputs.version }}"
          MINOR_VERSION=$(echo "$CURRENT_VERSION" | sed -E 's/^v?([0-9]+\.[0-9]+).*/\1/')

          echo "Current version: $CURRENT_VERSION"
          echo "Extracting all changes for minor version: $MINOR_VERSION"

          # Create grouped changelog file
          GROUPED_FILE="grouped_changelog_${MINOR_VERSION}.md"

          # Extract all entries for this minor version from CHANGELOG.md
          echo "# Release Notes for v${MINOR_VERSION}.x Series" > "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"
          echo "This release is part of the v${MINOR_VERSION}.x series. Below are all changes in this series:" >> "$GROUPED_FILE"
          echo "" >> "$GROUPED_FILE"

          # Parse CHANGELOG.md and extract all sections matching the minor version
          awk -v minor="$MINOR_VERSION" ' 
            /^## \[v?[0-9]+\.[0-9]+\.[0-9]+/ {
              version_str = $2
              gsub(/ \[v?/, "", version_str)
              gsub(/ /, "", version_str)
              split(version_str, version_parts, ".")
              version_minor = version_parts[1] "." version_parts[2]

              if (version_minor == minor) {
                in_section = 1
                print $0
                next
              } else {
                in_section = 0
              }
            }
            /^## \[/ && in_section { in_section = 0 }
            in_section { print }
          ' CHANGELOG.md >> "$GROUPED_FILE"

          # Store path for later use
          echo "grouped_changelog_file=$GROUPED_FILE" >> $GITHUB_OUTPUT
          echo "minor_version=$MINOR_VERSION" >> $GITHUB_OUTPUT

      - name: Prepare release assets
        shell: bash
        run: |
          mkdir -p assets
          # Collect all release files
          for dir in release-artifacts/release-*; do
            if [ -d "$dir" ]; then
              # Move main archive
              mv $dir/*.{tar.gz,zip} assets/ 2>/dev/null || true
              # Move Linux packages
              mv $dir/*.deb assets/ 2>/dev/null || true
              mv $dir/*.rpm assets/ 2>/dev/null || true
              mv $dir/*.AppImage assets/ 2>/dev/null || true
              # Move macOS pkg packages
              mv $dir/*.pkg assets/ 2>/dev/null || true
              # Collect benchmark results
              cp $dir/bench_results/*.json assets/ 2>/dev/null || true
            fi
          done
          echo "Collected assets:"
          ls -la assets/
      # Combine step removed; use CHANGELOG.md directly for release notes

      - name: "Dry-run: print release notes (act only)"
        if: ${{ github.actor == 'nektos/act' }}
        shell: bash
        run: |
          echo "--- CHANGELOG.md (dry-run) ---"
          cat CHANGELOG.md

      - name: Create or update GitHub Release (draft, upload assets first)
        if: ${{ github.actor != 'nektos/act' && steps.asset_check.outputs.file_count != '0' }}
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.meta.outputs.tag }}
          name: ${{ steps.meta.outputs.release_name }}
          body_path: CHANGELOG.md
          files: assets/*
          draft: true
          prerelease: ${{ steps.meta.outputs.prerelease }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Publish GitHub Release (flip draft=false)
        if: ${{ github.actor != 'nektos/act' && steps.asset_check.outputs.file_count != '0' }}
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "Installing gh CLI to publish release" >&2
            type -p curl >/dev/null || sudo apt-get update
            sudo apt-get install -y gh >/dev/null 2>&1 || true
          fi
          TAG="${{ steps.meta.outputs.tag }}"
          # publish the release after assets are uploaded
          gh release edit "$TAG" --draft=false --title "${{ steps.meta.outputs.release_name }}" --notes-file CHANGELOG.md \
            ${{ steps.meta.outputs.prerelease == 'true' && '--prerelease' || '--latest' }}

      - name: List release assets (post-upload)
        if: ${{ github.actor != 'nektos/act' }}
        shell: bash
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "Installing gh CLI for asset listing" >&2
            type -p curl >/dev/null || sudo apt-get update
            sudo apt-get install -y gh >/dev/null 2>&1 || true
          fi
          TAG="${{ steps.meta.outputs.tag }}"
          echo "Release assets for $TAG:" >&2
          gh release view "$TAG" --json assets --jq '.assets[].name' || echo "(Could not list assets)"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
